[{"node": {"avatar_large": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_large.png?m=1615112532", "name": "qna", "avatar_normal": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_normal.png?m=1615112532", "title": "问与答", "url": "https://www.v2ex.com/go/qna", "topics": 170389, "footer": "", "header": "一个更好的世界需要你持续地提出好问题。", "title_alternative": "Questions and Answers", "avatar_mini": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_mini.png?m=1615112532", "stars": 3188, "aliases": [], "root": false, "id": 12, "parent_node_name": "v2ex"}, "member": {"username": "Umenezumi", "website": "", "github": "", "psn": "", "avatar_normal": "https://cdn.v2ex.com/avatar/14c2/a6ad/393643_mini.png?m=1553527915", "bio": "", "url": "https://www.v2ex.com/u/Umenezumi", "tagline": "", "twitter": "", "created": 1553052026, "avatar_large": "https://cdn.v2ex.com/avatar/14c2/a6ad/393643_mini.png?m=1553527915", "avatar_mini": "https://cdn.v2ex.com/avatar/14c2/a6ad/393643_mini.png?m=1553527915", "location": "", "btc": "", "id": 393643}, "last_reply_by": "maninfog", "last_touched": 1616198334, "title": "公司征集一段代码印制在 T 恤上，过来取经了, 送键盘", "url": "https://www.v2ex.com/t/763130", "created": 1616123720, "content": "要求：\r\n - 立意清晰，表达合理\r\n - 凸显创意，写法高级\r\n - 正面代码长度简短，背面代码内容优美\r\n\r\n中了抽 1 楼，送出 cherry 机械键盘一把（公司的奖品）\r\n\r\n我司是一家游戏公司，slogan：`Make The World Happy !`", "content_rendered": "<p>要求：</p>\n<ul>\n<li>立意清晰，表达合理</li>\n<li>凸显创意，写法高级</li>\n<li>正面代码长度简短，背面代码内容优美</li>\n</ul>\n<p>中了抽 1 楼，送出 cherry 机械键盘一把（公司的奖品）</p>\n<p>我司是一家游戏公司，slogan：<code>Make The World Happy !</code></p>\n", "last_modified": 1616123720, "replies": 252, "id": 763130}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/d67d/8ab4/39_large.png?m=1615112014", "name": "android", "avatar_normal": "https://cdn.v2ex.com/navatar/d67d/8ab4/39_normal.png?m=1615112014", "title": "Android", "url": "https://www.v2ex.com/go/android", "topics": 8563, "footer": "", "header": "来自 <a href=\"/go/google\">Google</a> 的开放源代码智能手机平台。", "title_alternative": "Android", "avatar_mini": "https://cdn.v2ex.com/navatar/d67d/8ab4/39_mini.png?m=1615112014", "stars": 4731, "aliases": [], "root": false, "id": 39, "parent_node_name": "hardware"}, "member": {"username": "aw2350", "website": "", "github": null, "psn": null, "avatar_normal": "https://cdn.v2ex.com/avatar/4bb7/b5c3/504124_mini.png?m=1611716806", "bio": "", "url": "https://www.v2ex.com/u/aw2350", "tagline": "", "twitter": null, "created": 1597629937, "avatar_large": "https://cdn.v2ex.com/avatar/4bb7/b5c3/504124_mini.png?m=1611716806", "avatar_mini": "https://cdn.v2ex.com/avatar/4bb7/b5c3/504124_mini.png?m=1611716806", "location": "", "btc": null, "id": 504124}, "last_reply_by": "springlovvol", "last_touched": 1616202098, "title": "要换国产安卓手机了，要装哪些防国产流氓 app 的 app", "url": "https://www.v2ex.com/t/763097", "created": 1616120584, "content": "我的 iPhone6s 用了 4 年了，最近实在忍受不了在地铁里网络不好，随着系统升级续航也越来越差，但是 iOS 真的点赞，不用跟系统以及国产软件斗智斗勇，无奈苹果的信号以及续航太拉跨了\r\n看好了一款中兴的远航 5，5000 毫安的电池，跟老人机没啥区别了 ，在我认知里 zte 这种应该不会再系统里加一堆广告吧。。。\r\n我不玩游戏，也没那么 Geek，要求干净、隐私\r\n就一般软件应用的需求，但是我潜意识里不喜欢国产手机的各种“UI”，嵌入一堆广告，一堆推送，一堆没用的功能需求，所以我打心底里不喜欢某米某为这种\r\n试过一个某米海外版的 androidOne，相比于装 MIUI 的国内版本贵了将近 500，于是退货了\r\n看 tb 有什么针对安卓的黑域啥的，\r\n年纪大了，不爱折腾，就想问问，安卓机应该装什么软件去防国产软件", "content_rendered": "<p>我的 iPhone6s 用了 4 年了，最近实在忍受不了在地铁里网络不好，随着系统升级续航也越来越差，但是 iOS 真的点赞，不用跟系统以及国产软件斗智斗勇，无奈苹果的信号以及续航太拉跨了\n看好了一款中兴的远航 5，5000 毫安的电池，跟老人机没啥区别了 ，在我认知里 zte 这种应该不会再系统里加一堆广告吧。。。\n我不玩游戏，也没那么 Geek，要求干净、隐私\n就一般软件应用的需求，但是我潜意识里不喜欢国产手机的各种“UI”，嵌入一堆广告，一堆推送，一堆没用的功能需求，所以我打心底里不喜欢某米某为这种\n试过一个某米海外版的 androidOne，相比于装 MIUI 的国内版本贵了将近 500，于是退货了\n看 tb 有什么针对安卓的黑域啥的，\n年纪大了，不爱折腾，就想问问，安卓机应该装什么软件去防国产软件</p>\n", "last_modified": 1616123598, "replies": 152, "id": 763097}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_large.png?m=1615112532", "name": "qna", "avatar_normal": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_normal.png?m=1615112532", "title": "问与答", "url": "https://www.v2ex.com/go/qna", "topics": 170389, "footer": "", "header": "一个更好的世界需要你持续地提出好问题。", "title_alternative": "Questions and Answers", "avatar_mini": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_mini.png?m=1615112532", "stars": 3188, "aliases": [], "root": false, "id": 12, "parent_node_name": "v2ex"}, "member": {"username": "yitalin", "website": null, "github": null, "psn": null, "avatar_normal": "https://cdn.v2ex.com/gravatar/a2111a42c52f7c5047ac0bc9de186403?s=24&d=retro", "bio": null, "url": "https://www.v2ex.com/u/yitalin", "tagline": null, "twitter": null, "created": 1606200500, "avatar_large": "https://cdn.v2ex.com/gravatar/a2111a42c52f7c5047ac0bc9de186403?s=24&d=retro", "avatar_mini": "https://cdn.v2ex.com/gravatar/a2111a42c52f7c5047ac0bc9de186403?s=24&d=retro", "location": null, "btc": null, "id": 520203}, "last_reply_by": "hewigovens", "last_touched": 1616187307, "title": "2 万翻 10 倍变成了 20 万，我该继续持有吗？", "url": "https://www.v2ex.com/t/763109", "created": 1616121809, "content": "小弟当初购买是打算放个一两年，目前才 2 个月不到，现在又担心万一哪天开始大跌，大家觉得我该卖掉还是继续持仓\r\n![图片注释]( https://bit-images.bj.bcebos.com/bit-new/file/20210319/c4ft.jpg)\r\n![图片注释]( https://bit-images.bj.bcebos.com/bit-new/file/20210319/ue9t.jpg)\r\n![图片注释]( https://bit-images.bj.bcebos.com/bit-new/file/20210319/ozi4.jpg)", "content_rendered": "<p>小弟当初购买是打算放个一两年，目前才 2 个月不到，现在又担心万一哪天开始大跌，大家觉得我该卖掉还是继续持仓\n<img alt=\"图片注释\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://bit-images.bj.bcebos.com/bit-new/file/20210319/c4ft.jpg\"/>\n<img alt=\"图片注释\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://bit-images.bj.bcebos.com/bit-new/file/20210319/ue9t.jpg\"/>\n<img alt=\"图片注释\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://bit-images.bj.bcebos.com/bit-new/file/20210319/ozi4.jpg\"/></p>\n", "last_modified": 1616121852, "replies": 113, "id": 763109}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/94f6/d7e0/300_large.png?m=1614829460", "name": "programmer", "avatar_normal": "https://cdn.v2ex.com/navatar/94f6/d7e0/300_normal.png?m=1614829460", "title": "程序员", "url": "https://www.v2ex.com/go/programmer", "topics": 43830, "footer": "", "header": "While code monkeys are not eating bananas, they're coding.", "title_alternative": "Programmer", "avatar_mini": "https://cdn.v2ex.com/navatar/94f6/d7e0/300_mini.png?m=1614829460", "stars": 7298, "aliases": [], "root": false, "id": 300, "parent_node_name": "computer"}, "member": {"username": "code2019", "website": "", "github": null, "psn": null, "avatar_normal": "https://cdn.v2ex.com/avatar/e088/2fc7/415001_mini.png?m=1559473787", "bio": "", "url": "https://www.v2ex.com/u/code2019", "tagline": "", "twitter": null, "created": 1558599251, "avatar_large": "https://cdn.v2ex.com/avatar/e088/2fc7/415001_mini.png?m=1559473787", "avatar_mini": "https://cdn.v2ex.com/avatar/e088/2fc7/415001_mini.png?m=1559473787", "location": "", "btc": null, "id": 415001}, "last_reply_by": "oaix", "last_touched": 1616201700, "title": "并行用了两年的 macos 和 win10，感觉还是 win 生产力高，大家有同感吗？", "url": "https://www.v2ex.com/t/763209", "created": 1616137165, "content": "从小使用微软系统，感觉无论快捷键和生产力都比较高。MacBook 用了两年了，也学习了很多手势快捷键，但是用起来感觉还是不顺，但是屏幕是真的香，起初也是因为 retina 才买了 MacBook 。\n\n有时候总感觉想解决一件事情的时候 Windows 比较让人有目标感，特别现在也外接了 4k 显示器以后，感觉 Windows 更香了", "content_rendered": "<p>从小使用微软系统，感觉无论快捷键和生产力都比较高。MacBook 用了两年了，也学习了很多手势快捷键，但是用起来感觉还是不顺，但是屏幕是真的香，起初也是因为 retina 才买了 MacBook 。</p>\n<p>有时候总感觉想解决一件事情的时候 Windows 比较让人有目标感，特别现在也外接了 4k 显示器以后，感觉 Windows 更香了</p>\n", "last_modified": 1616137165, "replies": 84, "id": 763209}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/03af/dbd6/63_large.png?m=1596211530", "name": "java", "avatar_normal": "https://cdn.v2ex.com/navatar/03af/dbd6/63_normal.png?m=1596211530", "title": "Java", "url": "https://www.v2ex.com/go/java", "topics": 4300, "footer": "", "header": "The most popular programming language.", "title_alternative": "Java", "avatar_mini": "https://cdn.v2ex.com/navatar/03af/dbd6/63_mini.png?m=1596211530", "stars": 4397, "aliases": [], "root": false, "id": 63, "parent_node_name": "programming"}, "member": {"username": "liudaolunhuibl", "website": "", "github": null, "psn": null, "avatar_normal": "https://cdn.v2ex.com/avatar/37d4/6957/504746_mini.png?m=1600137063", "bio": "", "url": "https://www.v2ex.com/u/liudaolunhuibl", "tagline": "", "twitter": null, "created": 1597971891, "avatar_large": "https://cdn.v2ex.com/avatar/37d4/6957/504746_mini.png?m=1600137063", "avatar_mini": "https://cdn.v2ex.com/avatar/37d4/6957/504746_mini.png?m=1600137063", "location": "", "btc": null, "id": 504746}, "last_reply_by": "amon", "last_touched": 1616179999, "title": "都说 Java 是卷王之王，那 Java 到底有多卷？", "url": "https://www.v2ex.com/t/763188", "created": 1616134767, "content": "我先来：\r\n1 、部分公司换工作必须要严格根据你上一份工作的薪资来定，说死了涨幅最高 20%，并且要你提供流水\r\n2 、面试来越来越造火箭，继续卷下去完全有可能叫你详细解释一下 jvm 源码，现场手写一个 spring 框架等等\r\n3 、面试 java 不光要求你要会 java 还包括不限于精通 redis 、mq 、数据库、nosql 甚至大数据，还有各种设计模式、算法、架构。\r\n4 、你的基础一定要好，做过的项目一定要高大上，必问你项目多少 QPS，数据量多大", "content_rendered": "<p>我先来：\n1 、部分公司换工作必须要严格根据你上一份工作的薪资来定，说死了涨幅最高 20%，并且要你提供流水\n2 、面试来越来越造火箭，继续卷下去完全有可能叫你详细解释一下 jvm 源码，现场手写一个 spring 框架等等\n3 、面试 java 不光要求你要会 java 还包括不限于精通 redis 、mq 、数据库、nosql 甚至大数据，还有各种设计模式、算法、架构。\n4 、你的基础一定要好，做过的项目一定要高大上，必问你项目多少 QPS，数据量多大</p>\n", "last_modified": 1616134767, "replies": 75, "id": 763188}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/a3c6/5c29/108_large.png?m=1614829351", "name": "bb", "avatar_normal": "https://cdn.v2ex.com/navatar/a3c6/5c29/108_normal.png?m=1614829351", "title": "宽带症候群", "url": "https://www.v2ex.com/go/bb", "topics": 9223, "footer": "", "header": "网速很重要。比快更快。", "title_alternative": "Broadband Symptom Complex", "avatar_mini": "https://cdn.v2ex.com/navatar/a3c6/5c29/108_mini.png?m=1614829351", "stars": 4885, "aliases": [], "root": false, "id": 108, "parent_node_name": "geek"}, "member": {"username": "mingyuan2011", "website": "", "github": "", "psn": "", "avatar_normal": "https://cdn.v2ex.com/gravatar/b82fd16e3708c8be816e37676f7d2786?s=24&d=retro", "bio": "", "url": "https://www.v2ex.com/u/mingyuan2011", "tagline": "", "twitter": "", "created": 1428371286, "avatar_large": "https://cdn.v2ex.com/gravatar/b82fd16e3708c8be816e37676f7d2786?s=24&d=retro", "avatar_mini": "https://cdn.v2ex.com/gravatar/b82fd16e3708c8be816e37676f7d2786?s=24&d=retro", "location": "", "btc": "", "id": 109533}, "last_reply_by": "mikeluckybiy", "last_touched": 1616183332, "title": "上海电信十全十美套餐额外送的一路宽带被盗用了，要怎么处理？", "url": "https://www.v2ex.com/t/763086", "created": 1616119681, "content": "2018 年 12 月，我和我老婆去电信营业厅办理了 199 十全十美套餐，顺便给家里安一个固话。\r\n\r\n2021 年因为要搬家，要去办理宽带移机，发现多了一路宽带。\r\n是固话安装的第二天办理的。\r\n经过和客服沟通，解释说，是打 10000 号办理的套餐内额外附送的宽带。身份肯定是被盗用了，现在正在和电信纠缠这个事情；打算报警了。\r\n\r\n朋友们 有什么好的建议么？", "content_rendered": "2018 年 12 月，我和我老婆去电信营业厅办理了 199 十全十美套餐，顺便给家里安一个固话。<br /><br />2021 年因为要搬家，要去办理宽带移机，发现多了一路宽带。<br />是固话安装的第二天办理的。<br />经过和客服沟通，解释说，是打 10000 号办理的套餐内额外附送的宽带。身份肯定是被盗用了，现在正在和电信纠缠这个事情；打算报警了。<br /><br />朋友们 有什么好的建议么？", "last_modified": 1616119681, "replies": 67, "id": 763086}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/c9f0/f895/8_large.png?m=1615111905", "name": "iphone", "avatar_normal": "https://cdn.v2ex.com/navatar/c9f0/f895/8_normal.png?m=1615111905", "title": "iPhone", "url": "https://www.v2ex.com/go/iphone", "topics": 8398, "footer": "这里绝不讨论如何获得 iPhone 盗版软件、iTunes 黑卡之类。", "header": "Say hello to the future.", "title_alternative": "iPhone", "avatar_mini": "https://cdn.v2ex.com/navatar/c9f0/f895/8_mini.png?m=1615111905", "stars": 2620, "aliases": [], "root": false, "id": 8, "parent_node_name": "apple"}, "member": {"username": "comoyi", "website": null, "github": null, "psn": null, "avatar_normal": "https://cdn.v2ex.com/avatar/c354/1729/202025_mini.png?m=1479518961", "bio": null, "url": "https://www.v2ex.com/u/comoyi", "tagline": null, "twitter": null, "created": 1479518859, "avatar_large": "https://cdn.v2ex.com/avatar/c354/1729/202025_mini.png?m=1479518961", "avatar_mini": "https://cdn.v2ex.com/avatar/c354/1729/202025_mini.png?m=1479518961", "location": null, "btc": null, "id": 202025}, "last_reply_by": "Fqy", "last_touched": 1616204071, "title": "自从刘海屏问世，不再关注新手机了", "url": "https://www.v2ex.com/t/763174", "created": 1616131400, "content": "自从刘海屏问世以来，不再关注新出的手机了，这什么时候才是个头啊。\r\n\r\n但是我的 iPhone7 开始乏力了，微信语音经常会崩溃，是时候升级手机了。\r\n\r\n为了全面屏我宁愿不要前置摄像头，毕竟摄像头可以 type-c 外挂。", "content_rendered": "<p>自从刘海屏问世以来，不再关注新出的手机了，这什么时候才是个头啊。</p>\n<p>但是我的 iPhone7 开始乏力了，微信语音经常会崩溃，是时候升级手机了。</p>\n<p>为了全面屏我宁愿不要前置摄像头，毕竟摄像头可以 type-c 外挂。</p>\n", "last_modified": 1616131431, "replies": 65, "id": 763174}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/6cdd/60ea/184_large.png?m=1615111825", "name": "apple", "avatar_normal": "https://cdn.v2ex.com/navatar/6cdd/60ea/184_normal.png?m=1615111825", "title": "Apple", "url": "https://www.v2ex.com/go/apple", "topics": 14310, "footer": "", "header": "设计了 <a href=\"/go/watch\">Apple Watch</a>，<a href=\"/go/ipad\">iPad</a>，<a href=\"/go/iphone\">iPhone</a>，<a href=\"/go/imac\">iMac</a> 及 <a href=\"/go/mbp\">MacBook Pro</a> 等电子产品的美国公司。", "title_alternative": "Apple", "avatar_mini": "https://cdn.v2ex.com/navatar/6cdd/60ea/184_mini.png?m=1615111825", "stars": 1756, "aliases": [], "root": false, "id": 184, "parent_node_name": "hardware"}, "member": {"username": "letwewell", "website": null, "github": null, "psn": null, "avatar_normal": "https://cdn.v2ex.com/avatar/431f/a103/457159_mini.png?m=1612851011", "bio": null, "url": "https://www.v2ex.com/u/letwewell", "tagline": null, "twitter": null, "created": 1575366411, "avatar_large": "https://cdn.v2ex.com/avatar/431f/a103/457159_mini.png?m=1612851011", "avatar_mini": "https://cdn.v2ex.com/avatar/431f/a103/457159_mini.png?m=1612851011", "location": null, "btc": null, "id": 457159}, "last_reply_by": "paullee", "last_touched": 1616171125, "title": "官翻 Macbook air 又有货了 求问 8+256 前端开发够用吗？", "url": "https://www.v2ex.com/t/763163", "created": 1616127993, "content": "使用场景 Chrome + Vscode + node", "content_rendered": "<p>使用场景 Chrome + Vscode + node</p>\n", "last_modified": 1616127993, "replies": 56, "id": 763163}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/4ea0/6fbc/770_large.png?m=1614702720", "name": "career", "avatar_normal": "https://cdn.v2ex.com/navatar/4ea0/6fbc/770_normal.png?m=1614702720", "title": "职场话题", "url": "https://www.v2ex.com/go/career", "topics": 11054, "footer": "", "header": "这里，我们聊聊那些工作中遇到的开心和不开心的事。", "title_alternative": "Career", "avatar_mini": "https://cdn.v2ex.com/navatar/4ea0/6fbc/770_mini.png?m=1614702720", "stars": 1982, "aliases": [], "root": false, "id": 770, "parent_node_name": "work"}, "member": {"username": "zzzain46", "website": "", "github": "", "psn": "", "avatar_normal": "https://cdn.v2ex.com/avatar/4a8e/5197/428907_mini.png?m=1604121437", "bio": "", "url": "https://www.v2ex.com/u/zzzain46", "tagline": "", "twitter": "", "created": 1562918595, "avatar_large": "https://cdn.v2ex.com/avatar/4a8e/5197/428907_mini.png?m=1604121437", "avatar_mini": "https://cdn.v2ex.com/avatar/4a8e/5197/428907_mini.png?m=1604121437", "location": "", "btc": "", "id": 428907}, "last_reply_by": "Cloutain", "last_touched": 1616159266, "title": "五线城市民办学校，年薪 17W，大家觉得怎么样", "url": "https://www.v2ex.com/t/763155", "created": 1616126765, "content": "无编制。<br>\r\n学校给交的五险一金另算，不包含在工资内。<br>\r\n东部五线城市。<br>\r\n毗邻大城市。<br>", "content_rendered": "<p>无编制。<br/>\n学校给交的五险一金另算，不包含在工资内。<br/>\n东部五线城市。<br/>\n毗邻大城市。<br/></p>\n", "last_modified": 1616134255, "replies": 45, "id": 763155}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/94f6/d7e0/300_large.png?m=1614829460", "name": "programmer", "avatar_normal": "https://cdn.v2ex.com/navatar/94f6/d7e0/300_normal.png?m=1614829460", "title": "程序员", "url": "https://www.v2ex.com/go/programmer", "topics": 43830, "footer": "", "header": "While code monkeys are not eating bananas, they're coding.", "title_alternative": "Programmer", "avatar_mini": "https://cdn.v2ex.com/navatar/94f6/d7e0/300_mini.png?m=1614829460", "stars": 7298, "aliases": [], "root": false, "id": 300, "parent_node_name": "computer"}, "member": {"username": "kinglisky", "website": "", "github": "kinglisky", "psn": "", "avatar_normal": "https://cdn.v2ex.com/avatar/88f8/867d/170622_mini.png?m=1614831981", "bio": "", "url": "https://www.v2ex.com/u/kinglisky", "tagline": "", "twitter": "", "created": 1461598872, "avatar_large": "https://cdn.v2ex.com/avatar/88f8/867d/170622_mini.png?m=1614831981", "avatar_mini": "https://cdn.v2ex.com/avatar/88f8/867d/170622_mini.png?m=1614831981", "location": "", "btc": "", "id": 170622}, "last_reply_by": "steveway", "last_touched": 1616170769, "title": "从希卡文翻译谈谈 OCR 的简单实现", "url": "https://www.v2ex.com/t/763083", "created": 1616119242, "content": "最近摸鱼整的，水平有限~ \r\n\r\n\r\n## 希卡文\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-0.jpg)\r\n\r\n塞尔达玩家一定不会陌生，希卡文是游戏《塞尔达传说旷野之息》中一种虚构的文字，在希卡族的建筑上都能找到它的影子，之前实现了一个简单的[希卡文生成与翻译的工具]( http://nlush.com/zelda-words)，不过关键的文字解析实现的并不优雅，使用隐藏水印的方式将一些关键信息隐藏在导出的图片中，图片压缩后隐藏信息很容易丢失，导致解析失败。有兴趣的同学不妨看看上一篇文章：[摸一个塞尔达希卡文字转换器]( https://juejin.cn/post/6935836863844319239)。\r\n\r\n\r\n后面研究了下 [OCR]( https://zh.wikipedia.org/wiki/%E5%85%89%E5%AD%A6%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB) 的技术实现，手撸了个简单版的希卡文字 OCR 解析器，简单扯扯实现，水平有限望指点蛤~\r\n\r\n> 光学字符识别（英語：Optical Character Recognition，OCR ）是指对文本资料的图像文件进行分析识别处理，获取文字及版面信息的过程。\r\n\r\n工具地址在这：\r\n- 工具的演示地址在这：[https://kinglisky.github.io/zelda-words]( https://kinglisky.github.io/zelda-words)\r\n- 打不开的同学戳这里：[http://nlush.com/zelda-words/]( http://nlush.com/zelda-words/)\r\n- 仓库地址：[https://github.com/kinglisky/zelda-words]( https://github.com/kinglisky/zelda-words)\r\n\r\n虚构世界的文字往往是基于现实文字创造的，希卡文与英文字母数字与四个特殊符号（共 40 个字符）相对应，规则很简单，都在下图：\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-map.jpeg)\r\n\r\n我们导出的希卡文图片长这样：\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-1.jpeg)\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-2.jpeg)\r\n\r\n开始吧~\r\n\r\n## 图片二值化\r\n\r\n我们导出希卡文的图片颜色和文字排列都是不确定的，我们首先需要将图片做一个归一化处理，因为我们只关心图片的文字内容，所以首先要剔除颜色的干扰，我们可以将图片统一处理黑白色调的图片。\r\n\r\n这个过程称作[二值化\r\n]( https://zh.wikipedia.org/zh-hans/%E4%BA%8C%E5%80%BC%E5%8C%96)，二值化后的图片更能摒除干扰**突出图片的内容特征**，二值化后的图片可以很方便的被序列化生成图片指纹。\r\n\r\n> 二值化（英语：Binarization ）是图像分割的一种最简单的方法。二值化可以把灰度图像转换成二值图像。把大于某个临界灰度值的像素灰度设为灰度極大值，把小于这个值的像素灰度设为灰度極小值，从而实现二值化。\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-3.jpeg)\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-4.jpeg)\r\n\r\n图片二值化主要流程如下：\r\n- 图片灰度处理\r\n- 计算灰度图片的二值化阈值\r\n- 图片二值化\r\n\r\n### 图片灰度处理\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-2.jpeg)\r\n\r\n我们以上面的图片为例，图片的灰度处理比较简单，将 rgb 通道的颜色按 `r * 0.299 + g * 0.587 + b * 0.114` 的比值相加就能得到灰度值，因为灰度图片的 rgb 通道的值都是相同的，我们只取一个通道的值用于下一步计算。\r\n\r\n```JavaScript\r\nconst canvasToGray = (canvas) => {\r\n    const ctx = canvas.getContext('2d');\r\n    const data = ctx.getImageData(0, 0, canvas.width, canvas.height);\r\n    const calculateGray = (r, g, b) => parseInt(r * 0.299 + g * 0.587 + b * 0.114);\r\n    const grayData = [];\r\n    for (let x = 0; x < data.width; x++) {\r\n        for (let y = 0; y < data.height; y++) {\r\n            const idx = (x + y * data.width) * 4;\r\n            const r = data.data[idx + 0];\r\n            const g = data.data[idx + 1];\r\n            const b = data.data[idx + 2];\r\n            const gray = calculateGray(r, g, b);\r\n            grayData.push(gray);\r\n        }\r\n    }\r\n    return grayData;\r\n};\r\n```\r\n\r\n灰度处理后的图片如下：\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-5.png)\r\n### 二值化阈值\r\n\r\n阈值计算是图片二值化非常关键的一步，相关的算法也很多这里，这里我们先试试一种最简单的[均值哈希（ aHash ）]( https://baike.baidu.com/item/%E5%9D%87%E5%80%BC%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95)算法，算法很简单，求图片灰度像素的总和再除以像素点数量得出均值作为二值化的阈值。直接上代码：\r\n\r\n```JavaScript\r\nconst average = (grayData) => {\r\n    let sum = 0;\r\n    for (let i = 0; i < grayData.length; i += 1) {\r\n        sum += data[i];\r\n    }\r\n    return sum / grayData.length;\r\n};\r\n```\r\n\r\n其他计算阈值的算法还有：\r\n- [感知哈希 pHash]( https://baike.baidu.com/item/%E6%84%9F%E7%9F%A5%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95)\r\n- [大津算法 otsu]( https://zh.wikipedia.org/wiki/%E5%A4%A7%E6%B4%A5%E7%AE%97%E6%B3%95)\r\n\r\n感兴趣的同学可以了解下，otsu 的生成的二值化效果比较好，后面我们会有 otsu 来处理计算图片阈值，这里也贴一个 otsu 的实现：\r\n\r\n```JavaScript\r\nconst otsu = (grayData) => {\r\n    let ptr = 0;\r\n    // 记录 0-256 每个灰度值的数量，初始值为 0\r\n    let histData = Array(256).fill(0);\r\n    let total = grayData.length;\r\n\r\n    while (ptr < total) {\r\n        let h = grayData[ptr++];\r\n        histData[h]++;\r\n    }\r\n    // 总数(灰度值 x 数量)\r\n    let sum = 0;\r\n    for (let i = 0; i < 256; i++) {\r\n        sum += i * histData[i];\r\n    }\r\n    // 背景（小于阈值）的数量\r\n    let wB = 0;\r\n    // 前景（大于阈值）的数量 \r\n    let wF = 0;\r\n    // 背景图像（灰度 x 数量）总和\r\n    let sumB = 0;\r\n    // 存储最大类间方差值\r\n    let varMax = 0;\r\n    // 阈值\r\n    let threshold = 0;\r\n\r\n    for (let t = 0; t < 256; t++) {\r\n        // 背景（小于阈值）的数量累加\r\n        wB += histData[t];\r\n        if (wB === 0) continue;\r\n        // 前景（大于阈值）的数量累加\r\n        wF = total - wB;\r\n        if (wF === 0) break;\r\n        // 背景（灰度 x 数量）累加\r\n        sumB += t * histData[t];\r\n\r\n        // 背景（小于阈值）的平均灰度\r\n        let mB = sumB / wB;\r\n        // 前景（大于阈值）的平均灰度\r\n        let mF = (sum - sumB) / wF;\r\n        // 类间方差\r\n        let varBetween = wB * wF * (mB - mF) ** 2;\r\n\r\n        if (varBetween > varMax) {\r\n            varMax = varBetween;\r\n            threshold = t;\r\n        }\r\n    }\r\n\r\n    return threshold;\r\n};\r\n```\r\n\r\n### 图片二值化\r\n\r\n求得了阈值后我们再进行二值化就很简单了，不过这里有注意点，由于我们生成的图片**文字颜色和背景颜色**都是不确定的，我们求得阈值后，进行二值化时图片的背景颜色可能大于阈值，也有可能小于阈值，这样就没法统一所有图片的输出。这里我们需要规定二值化的图片输出，我们统一将背景的颜色设置为黑色（数值为 0 ），文字颜色设置为（ 255 白色）。\r\n\r\n由于我们生成的图片比较简单，图片的背景颜色取第一个像素的 rgb 值就能确认了，代码实现也很简单：\r\n\r\n```JavaScript\r\nconst binaryzationOutput = (originCanvas, threshold) => {\r\n    const ctx = originCanvas.getContext('2d');\r\n    const imageData = ctx.getImageData(0, 0, originCanvas.width, originCanvas.height);\r\n    const { width, height, data } = imageData;\r\n    // 第一像素的值即为背景色值\r\n    const head = (data[0] + data[1] + data[2]) / 3;\r\n    // 如果背景颜色大于阈值，则背景与文字的颜色的值则需要调换\r\n    const color = head > threshold\r\n        ? { foreground: 0, background: 255 }\r\n        : { foreground: 255, background: 0 };\r\n    for (let x = 0; x < width; x++) {\r\n        for (let y = 0; y < height; y++) {\r\n            const idx = (x + y * width) * 4;\r\n            const avg = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;\r\n            const v = avg > threshold ? color.foreground : color.background;\r\n            data[idx] = v;\r\n            data[idx + 1] = v;\r\n            data[idx + 2] = v;\r\n            data[idx + 3] = 255;\r\n        }\r\n    }\r\n    ctx.putImageData(imageData, 0, 0);\r\n    return originCanvas.toDataURL();\r\n}\r\n```\r\n\r\n还有一点需要注意下，这里二值处理的是**原图**，不是灰度处理后的图片。\r\n\r\n[完整的代码戳这]( https://github.com/kinglisky/zelda-words/blob/master/binarization.js)，二值化的图片如下：\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-6.png)\r\n\r\n## 文字切割\r\n\r\n经过上面的二值化处理我们已经将图片统一处理成黑底白字的图片，操作也特别简单，但生产级别的 OCR 实现往往还会涉及复杂的图片预处理，如图片的投影矫正、旋转矫正、裁剪、图片降噪、锐化等操作，这些预处理都是为了生成一张只包含文字信息的干净图片，因为会很大程度的影响下一步文字切割的效果。\r\n\r\n同字面描述一样，我们得想办法把一个个希卡文字提取出来，下面介绍一种简单的切割算法：**投影切割算法**。\r\n\r\n基本思路是：\r\n- 从上到下扫描图片每一行像素值，切割出文字所在的行\r\n- 从左到右扫描文字行每一列像素值，切割出单个文字\r\n\r\n### 切割行\r\n\r\n直接看图容易理解一点，先来切割行，我们图片大小是 700 x 600，从上至下扫描每一行的像素，**黑色像素记为 0 白色像素记为 1**，统计每行 1 的个数，我们可以得到下面折线图：\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-6.png)\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-8.png)\r\n\r\n横坐标对应图片的高度，纵坐标对应每行像素点的个数，我们可以很直观知道纵坐标为 0 的部分都是图片的空白间距，有值的部分则是文字内容所在的行，行高则是所跨越的区间。\r\n\r\n### 切割文字（切割列）\r\n通过上一步的扫描行我们已经可以切割出文字内容所占的行，下一步就是从左到右扫描文字行每列的像素值，同样是黑色记 0 白色记 1，统计 1 的个数，以第一行文字为例，其扫描的出来折线图如下：\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-9.png)\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-10.png)\r\n\r\n嗯，这个我知道，和切割行一样，只要将纵坐标有值得部分切出来就好！\r\n\r\n但这里会有问题，如果简单的按纵坐标有值的区间去拆分文字，最后一个文字就会被拆分左右两部部分：\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-13.jpeg)\r\n\r\n原因也很好理解，最后一个文字是左右结构的，中间有空隙隔开，所以文字被拆开了。\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-14.jpeg)\r\n\r\n可以看看下面的几个特殊的字符，一般拆分文字时我们需要考虑左右或者上下结构的文字。\r\n\r\n**上下结构的文字：**\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-15.jpeg)\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-17.png)\r\n\r\n**左右结构的文字：**\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-16.jpeg)\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-18.png)\r\n\r\n\r\n针对这些文字我们应该如何处理呢？我们可以很容易观察出希卡文字都是正方形的，那么每个字体宽高比例应该 1 : 1，如果我们能知道文字的宽度或者高度，那我们就是如何拼接文字区域了。如何计算文字的宽度或高度呢？\r\n\r\n处理其实很简单，针对整张图片，**横向扫描一次，纵向扫描一次**，可以得到文字内容在横纵方向上的投影大小，我们取横纵投影中**最大的区间**就是标准文字的大小，拆分时文字块不足标准大小则继续与下个投影区间的文字块合并，直到达到文字的标准大小。\r\n\r\n我们先来实现横纵向扫描和求取最大文字块的方法\r\n\r\n```JavaScript\r\n// 横纵向扫描\r\nfunction countPixel(imageData, isRow = false) {\r\n    const { width, height, data } = imageData;\r\n    const offsets = [0, 1, 2];\r\n    // 背景色\r\n    const head = offsets.map((i) => data[i]);\r\n    const pixel = [];\r\n    if (isRow) {\r\n        // 从上至下，横向扫描\r\n        for (let i = 0; i < height; i++) {\r\n            let count = 0;\r\n            for (let j = 0; j < width; j++) {\r\n                const index = (i * width + j) * 4;\r\n                const isEqual = offsets.every(\r\n                    (offset) => head[offset] === data[index + offset]\r\n                );\r\n                count += isEqual ? 0 : 1;\r\n            }\r\n            pixel.push(count);\r\n        }\r\n    } else {\r\n        // 从左到右，纵向扫描\r\n        for (let i = 0; i < width; i++) {\r\n            let count = 0;\r\n            for (let j = 0; j < height; j++) {\r\n                const index = (j * width + i) * 4;\r\n                const isEqual = offsets.every(\r\n                    (offset) => head[offset] === data[index + offset]\r\n                );\r\n                count += isEqual ? 0 : 1;\r\n            }\r\n            pixel.push(count);\r\n        }\r\n    }\r\n    return pixel;\r\n}\r\n\r\n// 拆分文字与背景区间\r\nfunction countRanges(counts) {\r\n    const groups = [];\r\n    let foreground = 0;\r\n    let background = 0;\r\n    counts.forEach((count) => {\r\n        if (count) {\r\n            foreground += 1;\r\n            if (background) {\r\n                groups.push({ background: true, value: background });\r\n                background = 0;\r\n            }\r\n        } else {\r\n            background += 1;\r\n            if (foreground) {\r\n                groups.push({ foreground: true, value: foreground });\r\n                foreground = 0;\r\n            }\r\n        }\r\n    });\r\n    if (foreground) {\r\n        groups.push({ foreground: true, value: foreground });\r\n    }\r\n    if (background) {\r\n        groups.push({ background: true, value: background });\r\n    }\r\n    return groups;\r\n}\r\n\r\n// 获取文字内容的最大区间\r\nfunction getMaxRange(data) {\r\n    return data.reduce((max, it) => {\r\n        if (it.foreground) {\r\n            return Math.max(max, it.value);\r\n        }\r\n        return max;\r\n    }, 0);\r\n}\r\n```\r\n\r\n计算图片中文字大小：\r\n\r\n```JavaScript\r\nconst imageData = {};\r\n// 逐行扫描\r\nconst rowsRanges = countRanges(countPixel(imageData, true));\r\n// 逐列扫描\r\nconst colsRanges = countRanges(countPixel(imageData, false));\r\n\r\n// 计算横纵像素分布得出字体内容的大小（字体正方形区域）\r\nconst fontRange = Math.max(\r\n    getMaxRange(rowsRanges),\r\n    getMaxRange(colsRanges)\r\n);\r\n```\r\n\r\n合并左右上下结构的文字区间：\r\n\r\n```JavaScript\r\n// 合并结构分离的文字区间\r\nfunction mergeRanges(data, size) {\r\n    const merge = [];\r\n    // chunks 用来保存小于标准文字大小区域\r\n    let chunks = [];\r\n    data.forEach((item) => {\r\n        if (chunks.length) {\r\n            chunks.push(item);\r\n            const value = chunks.reduce((sum, chunk) => sum + chunk.value, 0);\r\n            // 当前换成的区域大小大于或接近标准文字大小则合并成一块\r\n            if (value >= size || Math.pow(value - size, 2) < 4) {\r\n                merge.push({\r\n                    foreground: true,\r\n                    value,\r\n                });\r\n                chunks = [];\r\n            }\r\n            return;\r\n        }\r\n        // 区域内容小于标准文字大小是推入 chunks\r\n        if (item.foreground && item.value < size) {\r\n            chunks = [item];\r\n            return;\r\n        }\r\n        merge.push(item);\r\n    });\r\n    return merge;\r\n}\r\n```\r\n\r\n统一处理后的区块信息如下，我们只需按顺序裁剪出 `foreground` 与其对应的区块大小 `value` 就好了。\r\n\r\n```JavaScript\r\n[\r\n    {\r\n        \"background\": true,\r\n        \"value\": 115\r\n    },\r\n    {\r\n        \"foreground\": true,\r\n        \"value\": 70\r\n    },\r\n    {\r\n        \"background\": true,\r\n        \"value\": 30\r\n    },\r\n    {\r\n        \"foreground\": true,\r\n        \"value\": 70\r\n    },\r\n    {\r\n        \"background\": true,\r\n        \"value\": 30\r\n    },\r\n    {\r\n        \"foreground\": true,\r\n        \"value\": 70\r\n    },\r\n    {\r\n        \"background\": true,\r\n        \"value\": 30\r\n    },\r\n    {\r\n        \"foreground\": true,\r\n        \"value\": 70\r\n    },\r\n    {\r\n        \"background\": true,\r\n        \"value\": 115\r\n    }\r\n]\r\n```\r\n\r\n剩下的就是算各种偏移值然后从 cnavas 中切割出单个的文字块并记录下位置信息，[具体的实现可以戳这里]( https://github.com/kinglisky/zelda-words/blob/master/src/utils/image-ocr.ts#L221)，就不细讲了，切割出来文字内容如下：\r\n\r\n![]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-19.png)\r\n## 相似图片检测\r\n\r\n切割出文字后，剩下的就是文字的翻译了。对于希卡文我们知道它与英文的映射规则，每个希卡符号背后对都对应一个英文符号，我们可以生成 40 个英文字符对应的希卡符号图片作为标准字符图片，那么希卡图片翻译就可以简单理解为：将切割的图片与已知的 40 标准字符图片逐个进行**相似性比较**，找出相似度最高的图片就是目标字符。\r\n\r\n![abcdefghijklmnopqrstuvwxyz0123456789.-!? 对应的希卡符号]( https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-7.jpeg)\r\n\r\n上面为 `abcdefghijklmnopqrstuvwxyz0123456789.-!?` 对应的希卡符号。\r\n\r\n我们该如何进行比较两张图片的相似性呢？其实我们已经完成了很大一部分工作，就差临门一脚了。既然一张已经二值化处理成了黑白图片，我们将图片的**黑色像素输出为 0 白色部分输出为 1 **这样就可以得到一张图片的二进制哈希，至于两张图片的相似性就是比较两张图片哈希同一位置的**差异个数**，其实就是计算两张图片的哈希的[汉明距离]( https://zh.wikipedia.org/zh-hans/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB)，汉明距离越小，两张图片越相似。我们只需要简单改变下二值化输出的代码就能得到图片的哈希。\r\n\r\n```JavaScript\r\nconst binaryzationHash = (originCanvas, threshold) => { \r\n    const ctx = originCanvas.getContext('2d');\r\n    const imageData = ctx.getImageData(0, 0, originCanvas.width, originCanvas.height);\r\n    const { width, height, data } = imageData;\r\n    // 第一像素的值即为背景色值\r\n    const head = (data[0] + data[1] + data[2]) / 3;\r\n    // 如果背景颜色大于阈值，则背景与文字的颜色的值则需要调换\r\n    const color = head > threshold\r\n        ? { foreground: 0, background: 255 }\r\n        : { foreground: 255, background: 0 };\r\n    const hash = [];\r\n    for (let x = 0; x < width; x++) {\r\n        for (let y = 0; y < height; y++) {\r\n            const idx = (x + y * width) * 4;\r\n            const avg = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;\r\n            const v = avg > threshold ? color.foreground : color.background;\r\n            hash.push(v ? 1 : 0);\r\n        }\r\n    }\r\n    return hash;\r\n}\r\n```\r\n\r\n汉明距离的比较也十分简单：\r\n\r\n```JavaScript\r\nconst hammingDistance = (hash1, hash2) => {\r\n    let count = 0;\r\n    hash1.forEach((it, index) => {\r\n        count += it ^ hash2[index];\r\n    });\r\n    return count;\r\n};\r\n```\r\n\r\n这就是相似图片比较最核心的代码了，因为我们并不能保证切割出来的文字块大小能标准图片一样，所以我们会将切割图片和标准图片都缩小成 8 x 8 大小再进行比较，两张图片相似性比较主要流程大致如下：\r\n- 将比较的图片都缩小成 8 x 8\r\n- 图片灰度化处理\r\n- 计算二值化阈值\r\n- 图片二值化计算图片哈希\r\n- 比较两张图片哈希的汉明距离\r\n\r\n之前详细整理过一篇相似图片识别的文章，对此感兴趣的同学可以看看这篇文章：[相似图片识别的朴素实现]( https://juejin.cn/post/6926181310868226061)。\r\n\r\n回到我们希卡文翻译上，所以我们现在要做只有三步：\r\n1. 40 个标准图片统一缩小成 8 x 8 并生成对应的图片哈希\r\n2. 切割出的文字图片统一缩小成 8 x 8 并生成对应的图片哈希\r\n3. 切割出文字哈希逐个与 40 个标准图片哈希比较，挑选出差异（相似度最高的）最小就是目标字母\r\n\r\n\r\n代码实现也比较简单：\r\n\r\n```JavaScript\r\nasync function createImageFingerprints(image) {\r\n    const contents = splitImage(image);\r\n    return contents.map(({ canvas, ...args }) => {\r\n        // 统一缩小到 8 像素\r\n        const imageData = resizeCanvas(canvas, 8);\r\n        const hash = binaryzationOutput(imageData);\r\n        return {\r\n            ...args,\r\n            hash,\r\n        };\r\n    });\r\n}\r\n\r\n// 生成标准字符指纹\r\nfunction createSymbols(fingerprints) {\r\n    const WORDS = 'abcdefghijklmnopqrstuvwxyz0123456789.-!?';\r\n    return fingerprints.map((it, index) => {\r\n        return {\r\n            name: WORDS[index],\r\n            value: it.hash,\r\n        };\r\n    });\r\n}\r\n\r\n// 匹配出最相似的字符\r\nfunction mapSymbols(fingerprints, symbols) {\r\n    return fingerprints.map(({ hash, ...position }) => {\r\n        const isEmpty = hash.every((v:) => v === hash[0]);\r\n        if (isEmpty) {\r\n            return ' ';\r\n        }\r\n        let diff = Number.MAX_SAFE_INTEGER;\r\n        let word = '*';\r\n        symbols.forEach((symbol) => {\r\n            const distance = hammingDistance(hash, symbol.value);\r\n            // 汉明距离大于标识相似度偏差较大排除\r\n            if (distance < diff) {\r\n                diff = distance;\r\n                word = symbol.name;\r\n            }\r\n        });\r\n        return {\r\n            ...position,\r\n            word,\r\n            diff,\r\n        };\r\n    });\r\n}\r\n```\r\n\r\n使用大概是这样的：\r\n\r\n```JavaScript\r\n/** \r\n * @param imageUrl 解析的图片\r\n * @param mapUrl 标准字符图片\r\n*/\r\nexport async function readMetaInfo(imageUrl, mapUrl) {\r\n    const mapImage = await loadImage(mapUrl);\r\n    const mapImageFingerprints = await createImageFingerprints(mapImage, false);\r\n    const symbols = createSymbols(mapImageFingerprints);\r\n    const readImage = await loadImage(imageUrl);\r\n    const readImageFingerprints = await createImageFingerprints(\r\n        readImage,\r\n        true\r\n    );\r\n    const results = mapSymbols(readImageFingerprints, symbols);\r\n    console.log(results);\r\n}\r\n```\r\n\r\n[完整代码实现可以戳这里]( https://github.com/kinglisky/zelda-words/blob/master/src/utils/image-ocr.ts#L390)，至此一个简简简单版的希卡文 OCR 翻译器就完成了~\r\n\r\n\r\n## 其他\r\n\r\n- [摸一个塞尔达希卡文字转换器]( https://juejin.cn/post/6935836863844319239/)\r\n- [相似图片识别的朴素实现]( https://juejin.cn/post/6926181310868226061)\r\n- [利用 JS 实现多种图片相似度算法]( https://segmentfault.com/a/1190000021236326)\r\n- [文字切割算法-基于投影的切割]( https://blog.csdn.net/Print_lin/article/details/80143002?spm=1001.2014.3001.5501)\r\n- [文字切割算法-投影切割优化]( https://blog.csdn.net/Print_lin/article/details/80335236)\r\n\r\n摸鱼做的一个小东西，粗略的了解了下 OCR 的实现还是很开心的。", "content_rendered": "<p>最近摸鱼整的，水平有限~ </p>\n<h2>希卡文</h2>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-0.jpg\"/></p>\n<p>塞尔达玩家一定不会陌生，希卡文是游戏《塞尔达传说旷野之息》中一种虚构的文字，在希卡族的建筑上都能找到它的影子，之前实现了一个简单的<a href=\"http://nlush.com/zelda-words\" rel=\"nofollow\">希卡文生成与翻译的工具</a>，不过关键的文字解析实现的并不优雅，使用隐藏水印的方式将一些关键信息隐藏在导出的图片中，图片压缩后隐藏信息很容易丢失，导致解析失败。有兴趣的同学不妨看看上一篇文章：<a href=\"https://juejin.cn/post/6935836863844319239\" rel=\"nofollow\">摸一个塞尔达希卡文字转换器</a>。</p>\n<p>后面研究了下 <a href=\"https://zh.wikipedia.org/wiki/%E5%85%89%E5%AD%A6%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB\" rel=\"nofollow\">OCR</a> 的技术实现，手撸了个简单版的希卡文字 OCR 解析器，简单扯扯实现，水平有限望指点蛤~</p>\n<blockquote>\n<p>光学字符识别（英語：Optical Character Recognition，OCR ）是指对文本资料的图像文件进行分析识别处理，获取文字及版面信息的过程。</p>\n</blockquote>\n<p>工具地址在这：</p>\n<ul>\n<li>工具的演示地址在这：<a href=\"https://kinglisky.github.io/zelda-words\" rel=\"nofollow\">https://kinglisky.github.io/zelda-words</a></li>\n<li>打不开的同学戳这里：<a href=\"http://nlush.com/zelda-words/\" rel=\"nofollow\">http://nlush.com/zelda-words/</a></li>\n<li>仓库地址：<a href=\"https://github.com/kinglisky/zelda-words\" rel=\"nofollow\">https://github.com/kinglisky/zelda-words</a></li>\n</ul>\n<p>虚构世界的文字往往是基于现实文字创造的，希卡文与英文字母数字与四个特殊符号（共 40 个字符）相对应，规则很简单，都在下图：</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-map.jpeg\"/></p>\n<p>我们导出的希卡文图片长这样：</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-1.jpeg\"/>\n<img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-2.jpeg\"/></p>\n<p>开始吧~</p>\n<h2>图片二值化</h2>\n<p>我们导出希卡文的图片颜色和文字排列都是不确定的，我们首先需要将图片做一个归一化处理，因为我们只关心图片的文字内容，所以首先要剔除颜色的干扰，我们可以将图片统一处理黑白色调的图片。</p>\n<p>这个过程称作<a href=\"https://zh.wikipedia.org/zh-hans/%E4%BA%8C%E5%80%BC%E5%8C%96\" rel=\"nofollow\">二值化\n</a>，二值化后的图片更能摒除干扰<strong>突出图片的内容特征</strong>，二值化后的图片可以很方便的被序列化生成图片指纹。</p>\n<blockquote>\n<p>二值化（英语：Binarization ）是图像分割的一种最简单的方法。二值化可以把灰度图像转换成二值图像。把大于某个临界灰度值的像素灰度设为灰度極大值，把小于这个值的像素灰度设为灰度極小值，从而实现二值化。</p>\n</blockquote>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-3.jpeg\"/>\n<img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-4.jpeg\"/></p>\n<p>图片二值化主要流程如下：</p>\n<ul>\n<li>图片灰度处理</li>\n<li>计算灰度图片的二值化阈值</li>\n<li>图片二值化</li>\n</ul>\n<h3>图片灰度处理</h3>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-2.jpeg\"/></p>\n<p>我们以上面的图片为例，图片的灰度处理比较简单，将 rgb 通道的颜色按 <code>r * 0.299 + g * 0.587 + b * 0.114</code> 的比值相加就能得到灰度值，因为灰度图片的 rgb 通道的值都是相同的，我们只取一个通道的值用于下一步计算。</p>\n<pre><code class=\"language-JavaScript\">const canvasToGray = (canvas) =&gt; {\n    const ctx = canvas.getContext('2d');\n    const data = ctx.getImageData(0, 0, canvas.width, canvas.height);\n    const calculateGray = (r, g, b) =&gt; parseInt(r * 0.299 + g * 0.587 + b * 0.114);\n    const grayData = [];\n    for (let x = 0; x &lt; data.width; x++) {\n        for (let y = 0; y &lt; data.height; y++) {\n            const idx = (x + y * data.width) * 4;\n            const r = data.data[idx + 0];\n            const g = data.data[idx + 1];\n            const b = data.data[idx + 2];\n            const gray = calculateGray(r, g, b);\n            grayData.push(gray);\n        }\n    }\n    return grayData;\n};\n</code></pre>\n<p>灰度处理后的图片如下：</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-5.png\"/></p>\n<h3>二值化阈值</h3>\n<p>阈值计算是图片二值化非常关键的一步，相关的算法也很多这里，这里我们先试试一种最简单的<a href=\"https://baike.baidu.com/item/%E5%9D%87%E5%80%BC%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95\" rel=\"nofollow\">均值哈希（ aHash ）</a>算法，算法很简单，求图片灰度像素的总和再除以像素点数量得出均值作为二值化的阈值。直接上代码：</p>\n<pre><code class=\"language-JavaScript\">const average = (grayData) =&gt; {\n    let sum = 0;\n    for (let i = 0; i &lt; grayData.length; i += 1) {\n        sum += data[i];\n    }\n    return sum / grayData.length;\n};\n</code></pre>\n<p>其他计算阈值的算法还有：</p>\n<ul>\n<li><a href=\"https://baike.baidu.com/item/%E6%84%9F%E7%9F%A5%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95\" rel=\"nofollow\">感知哈希 pHash</a></li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%A4%A7%E6%B4%A5%E7%AE%97%E6%B3%95\" rel=\"nofollow\">大津算法 otsu</a></li>\n</ul>\n<p>感兴趣的同学可以了解下，otsu 的生成的二值化效果比较好，后面我们会有 otsu 来处理计算图片阈值，这里也贴一个 otsu 的实现：</p>\n<pre><code class=\"language-JavaScript\">const otsu = (grayData) =&gt; {\n    let ptr = 0;\n    // 记录 0-256 每个灰度值的数量，初始值为 0\n    let histData = Array(256).fill(0);\n    let total = grayData.length;\n\n    while (ptr &lt; total) {\n        let h = grayData[ptr++];\n        histData[h]++;\n    }\n    // 总数(灰度值 x 数量)\n    let sum = 0;\n    for (let i = 0; i &lt; 256; i++) {\n        sum += i * histData[i];\n    }\n    // 背景（小于阈值）的数量\n    let wB = 0;\n    // 前景（大于阈值）的数量 \n    let wF = 0;\n    // 背景图像（灰度 x 数量）总和\n    let sumB = 0;\n    // 存储最大类间方差值\n    let varMax = 0;\n    // 阈值\n    let threshold = 0;\n\n    for (let t = 0; t &lt; 256; t++) {\n        // 背景（小于阈值）的数量累加\n        wB += histData[t];\n        if (wB === 0) continue;\n        // 前景（大于阈值）的数量累加\n        wF = total - wB;\n        if (wF === 0) break;\n        // 背景（灰度 x 数量）累加\n        sumB += t * histData[t];\n\n        // 背景（小于阈值）的平均灰度\n        let mB = sumB / wB;\n        // 前景（大于阈值）的平均灰度\n        let mF = (sum - sumB) / wF;\n        // 类间方差\n        let varBetween = wB * wF * (mB - mF) ** 2;\n\n        if (varBetween &gt; varMax) {\n            varMax = varBetween;\n            threshold = t;\n        }\n    }\n\n    return threshold;\n};\n</code></pre>\n<h3>图片二值化</h3>\n<p>求得了阈值后我们再进行二值化就很简单了，不过这里有注意点，由于我们生成的图片<strong>文字颜色和背景颜色</strong>都是不确定的，我们求得阈值后，进行二值化时图片的背景颜色可能大于阈值，也有可能小于阈值，这样就没法统一所有图片的输出。这里我们需要规定二值化的图片输出，我们统一将背景的颜色设置为黑色（数值为 0 ），文字颜色设置为（ 255 白色）。</p>\n<p>由于我们生成的图片比较简单，图片的背景颜色取第一个像素的 rgb 值就能确认了，代码实现也很简单：</p>\n<pre><code class=\"language-JavaScript\">const binaryzationOutput = (originCanvas, threshold) =&gt; {\n    const ctx = originCanvas.getContext('2d');\n    const imageData = ctx.getImageData(0, 0, originCanvas.width, originCanvas.height);\n    const { width, height, data } = imageData;\n    // 第一像素的值即为背景色值\n    const head = (data[0] + data[1] + data[2]) / 3;\n    // 如果背景颜色大于阈值，则背景与文字的颜色的值则需要调换\n    const color = head &gt; threshold\n        ? { foreground: 0, background: 255 }\n        : { foreground: 255, background: 0 };\n    for (let x = 0; x &lt; width; x++) {\n        for (let y = 0; y &lt; height; y++) {\n            const idx = (x + y * width) * 4;\n            const avg = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;\n            const v = avg &gt; threshold ? color.foreground : color.background;\n            data[idx] = v;\n            data[idx + 1] = v;\n            data[idx + 2] = v;\n            data[idx + 3] = 255;\n        }\n    }\n    ctx.putImageData(imageData, 0, 0);\n    return originCanvas.toDataURL();\n}\n</code></pre>\n<p>还有一点需要注意下，这里二值处理的是<strong>原图</strong>，不是灰度处理后的图片。</p>\n<p><a href=\"https://github.com/kinglisky/zelda-words/blob/master/binarization.js\" rel=\"nofollow\">完整的代码戳这</a>，二值化的图片如下：</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-6.png\"/></p>\n<h2>文字切割</h2>\n<p>经过上面的二值化处理我们已经将图片统一处理成黑底白字的图片，操作也特别简单，但生产级别的 OCR 实现往往还会涉及复杂的图片预处理，如图片的投影矫正、旋转矫正、裁剪、图片降噪、锐化等操作，这些预处理都是为了生成一张只包含文字信息的干净图片，因为会很大程度的影响下一步文字切割的效果。</p>\n<p>同字面描述一样，我们得想办法把一个个希卡文字提取出来，下面介绍一种简单的切割算法：<strong>投影切割算法</strong>。</p>\n<p>基本思路是：</p>\n<ul>\n<li>从上到下扫描图片每一行像素值，切割出文字所在的行</li>\n<li>从左到右扫描文字行每一列像素值，切割出单个文字</li>\n</ul>\n<h3>切割行</h3>\n<p>直接看图容易理解一点，先来切割行，我们图片大小是 700 x 600，从上至下扫描每一行的像素，<strong>黑色像素记为 0 白色像素记为 1</strong>，统计每行 1 的个数，我们可以得到下面折线图：</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-6.png\"/></p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-8.png\"/></p>\n<p>横坐标对应图片的高度，纵坐标对应每行像素点的个数，我们可以很直观知道纵坐标为 0 的部分都是图片的空白间距，有值的部分则是文字内容所在的行，行高则是所跨越的区间。</p>\n<h3>切割文字（切割列）</h3>\n<p>通过上一步的扫描行我们已经可以切割出文字内容所占的行，下一步就是从左到右扫描文字行每列的像素值，同样是黑色记 0 白色记 1，统计 1 的个数，以第一行文字为例，其扫描的出来折线图如下：</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-9.png\"/></p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-10.png\"/></p>\n<p>嗯，这个我知道，和切割行一样，只要将纵坐标有值得部分切出来就好！</p>\n<p>但这里会有问题，如果简单的按纵坐标有值的区间去拆分文字，最后一个文字就会被拆分左右两部部分：</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-13.jpeg\"/></p>\n<p>原因也很好理解，最后一个文字是左右结构的，中间有空隙隔开，所以文字被拆开了。</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-14.jpeg\"/></p>\n<p>可以看看下面的几个特殊的字符，一般拆分文字时我们需要考虑左右或者上下结构的文字。</p>\n<p><strong>上下结构的文字：</strong></p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-15.jpeg\"/></p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-17.png\"/></p>\n<p><strong>左右结构的文字：</strong></p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-16.jpeg\"/></p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-18.png\"/></p>\n<p>针对这些文字我们应该如何处理呢？我们可以很容易观察出希卡文字都是正方形的，那么每个字体宽高比例应该 1 : 1，如果我们能知道文字的宽度或者高度，那我们就是如何拼接文字区域了。如何计算文字的宽度或高度呢？</p>\n<p>处理其实很简单，针对整张图片，<strong>横向扫描一次，纵向扫描一次</strong>，可以得到文字内容在横纵方向上的投影大小，我们取横纵投影中<strong>最大的区间</strong>就是标准文字的大小，拆分时文字块不足标准大小则继续与下个投影区间的文字块合并，直到达到文字的标准大小。</p>\n<p>我们先来实现横纵向扫描和求取最大文字块的方法</p>\n<pre><code class=\"language-JavaScript\">// 横纵向扫描\nfunction countPixel(imageData, isRow = false) {\n    const { width, height, data } = imageData;\n    const offsets = [0, 1, 2];\n    // 背景色\n    const head = offsets.map((i) =&gt; data[i]);\n    const pixel = [];\n    if (isRow) {\n        // 从上至下，横向扫描\n        for (let i = 0; i &lt; height; i++) {\n            let count = 0;\n            for (let j = 0; j &lt; width; j++) {\n                const index = (i * width + j) * 4;\n                const isEqual = offsets.every(\n                    (offset) =&gt; head[offset] === data[index + offset]\n                );\n                count += isEqual ? 0 : 1;\n            }\n            pixel.push(count);\n        }\n    } else {\n        // 从左到右，纵向扫描\n        for (let i = 0; i &lt; width; i++) {\n            let count = 0;\n            for (let j = 0; j &lt; height; j++) {\n                const index = (j * width + i) * 4;\n                const isEqual = offsets.every(\n                    (offset) =&gt; head[offset] === data[index + offset]\n                );\n                count += isEqual ? 0 : 1;\n            }\n            pixel.push(count);\n        }\n    }\n    return pixel;\n}\n\n// 拆分文字与背景区间\nfunction countRanges(counts) {\n    const groups = [];\n    let foreground = 0;\n    let background = 0;\n    counts.forEach((count) =&gt; {\n        if (count) {\n            foreground += 1;\n            if (background) {\n                groups.push({ background: true, value: background });\n                background = 0;\n            }\n        } else {\n            background += 1;\n            if (foreground) {\n                groups.push({ foreground: true, value: foreground });\n                foreground = 0;\n            }\n        }\n    });\n    if (foreground) {\n        groups.push({ foreground: true, value: foreground });\n    }\n    if (background) {\n        groups.push({ background: true, value: background });\n    }\n    return groups;\n}\n\n// 获取文字内容的最大区间\nfunction getMaxRange(data) {\n    return data.reduce((max, it) =&gt; {\n        if (it.foreground) {\n            return Math.max(max, it.value);\n        }\n        return max;\n    }, 0);\n}\n</code></pre>\n<p>计算图片中文字大小：</p>\n<pre><code class=\"language-JavaScript\">const imageData = {};\n// 逐行扫描\nconst rowsRanges = countRanges(countPixel(imageData, true));\n// 逐列扫描\nconst colsRanges = countRanges(countPixel(imageData, false));\n\n// 计算横纵像素分布得出字体内容的大小（字体正方形区域）\nconst fontRange = Math.max(\n    getMaxRange(rowsRanges),\n    getMaxRange(colsRanges)\n);\n</code></pre>\n<p>合并左右上下结构的文字区间：</p>\n<pre><code class=\"language-JavaScript\">// 合并结构分离的文字区间\nfunction mergeRanges(data, size) {\n    const merge = [];\n    // chunks 用来保存小于标准文字大小区域\n    let chunks = [];\n    data.forEach((item) =&gt; {\n        if (chunks.length) {\n            chunks.push(item);\n            const value = chunks.reduce((sum, chunk) =&gt; sum + chunk.value, 0);\n            // 当前换成的区域大小大于或接近标准文字大小则合并成一块\n            if (value &gt;= size || Math.pow(value - size, 2) &lt; 4) {\n                merge.push({\n                    foreground: true,\n                    value,\n                });\n                chunks = [];\n            }\n            return;\n        }\n        // 区域内容小于标准文字大小是推入 chunks\n        if (item.foreground &amp;&amp; item.value &lt; size) {\n            chunks = [item];\n            return;\n        }\n        merge.push(item);\n    });\n    return merge;\n}\n</code></pre>\n<p>统一处理后的区块信息如下，我们只需按顺序裁剪出 <code>foreground</code> 与其对应的区块大小 <code>value</code> 就好了。</p>\n<pre><code class=\"language-JavaScript\">[\n    {\n        \"background\": true,\n        \"value\": 115\n    },\n    {\n        \"foreground\": true,\n        \"value\": 70\n    },\n    {\n        \"background\": true,\n        \"value\": 30\n    },\n    {\n        \"foreground\": true,\n        \"value\": 70\n    },\n    {\n        \"background\": true,\n        \"value\": 30\n    },\n    {\n        \"foreground\": true,\n        \"value\": 70\n    },\n    {\n        \"background\": true,\n        \"value\": 30\n    },\n    {\n        \"foreground\": true,\n        \"value\": 70\n    },\n    {\n        \"background\": true,\n        \"value\": 115\n    }\n]\n</code></pre>\n<p>剩下的就是算各种偏移值然后从 cnavas 中切割出单个的文字块并记录下位置信息，<a href=\"https://github.com/kinglisky/zelda-words/blob/master/src/utils/image-ocr.ts#L221\" rel=\"nofollow\">具体的实现可以戳这里</a>，就不细讲了，切割出来文字内容如下：</p>\n<p><img alt=\"\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-19.png\"/></p>\n<h2>相似图片检测</h2>\n<p>切割出文字后，剩下的就是文字的翻译了。对于希卡文我们知道它与英文的映射规则，每个希卡符号背后对都对应一个英文符号，我们可以生成 40 个英文字符对应的希卡符号图片作为标准字符图片，那么希卡图片翻译就可以简单理解为：将切割的图片与已知的 40 标准字符图片逐个进行<strong>相似性比较</strong>，找出相似度最高的图片就是目标字符。</p>\n<p><img alt=\"abcdefghijklmnopqrstuvwxyz0123456789.-!? 对应的希卡符号\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://markdown-write.oss-cn-hangzhou.aliyuncs.com/ocr-7.jpeg\"/></p>\n<p>上面为 <code>abcdefghijklmnopqrstuvwxyz0123456789.-!?</code> 对应的希卡符号。</p>\n<p>我们该如何进行比较两张图片的相似性呢？其实我们已经完成了很大一部分工作，就差临门一脚了。既然一张已经二值化处理成了黑白图片，我们将图片的<strong>黑色像素输出为 0 白色部分输出为 1 <strong>这样就可以得到一张图片的二进制哈希，至于两张图片的相似性就是比较两张图片哈希同一位置的</strong>差异个数</strong>，其实就是计算两张图片的哈希的<a href=\"https://zh.wikipedia.org/zh-hans/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB\" rel=\"nofollow\">汉明距离</a>，汉明距离越小，两张图片越相似。我们只需要简单改变下二值化输出的代码就能得到图片的哈希。</p>\n<pre><code class=\"language-JavaScript\">const binaryzationHash = (originCanvas, threshold) =&gt; { \n    const ctx = originCanvas.getContext('2d');\n    const imageData = ctx.getImageData(0, 0, originCanvas.width, originCanvas.height);\n    const { width, height, data } = imageData;\n    // 第一像素的值即为背景色值\n    const head = (data[0] + data[1] + data[2]) / 3;\n    // 如果背景颜色大于阈值，则背景与文字的颜色的值则需要调换\n    const color = head &gt; threshold\n        ? { foreground: 0, background: 255 }\n        : { foreground: 255, background: 0 };\n    const hash = [];\n    for (let x = 0; x &lt; width; x++) {\n        for (let y = 0; y &lt; height; y++) {\n            const idx = (x + y * width) * 4;\n            const avg = (data[idx] + data[idx + 1] + data[idx + 2]) / 3;\n            const v = avg &gt; threshold ? color.foreground : color.background;\n            hash.push(v ? 1 : 0);\n        }\n    }\n    return hash;\n}\n</code></pre>\n<p>汉明距离的比较也十分简单：</p>\n<pre><code class=\"language-JavaScript\">const hammingDistance = (hash1, hash2) =&gt; {\n    let count = 0;\n    hash1.forEach((it, index) =&gt; {\n        count += it ^ hash2[index];\n    });\n    return count;\n};\n</code></pre>\n<p>这就是相似图片比较最核心的代码了，因为我们并不能保证切割出来的文字块大小能标准图片一样，所以我们会将切割图片和标准图片都缩小成 8 x 8 大小再进行比较，两张图片相似性比较主要流程大致如下：</p>\n<ul>\n<li>将比较的图片都缩小成 8 x 8</li>\n<li>图片灰度化处理</li>\n<li>计算二值化阈值</li>\n<li>图片二值化计算图片哈希</li>\n<li>比较两张图片哈希的汉明距离</li>\n</ul>\n<p>之前详细整理过一篇相似图片识别的文章，对此感兴趣的同学可以看看这篇文章：<a href=\"https://juejin.cn/post/6926181310868226061\" rel=\"nofollow\">相似图片识别的朴素实现</a>。</p>\n<p>回到我们希卡文翻译上，所以我们现在要做只有三步：</p>\n<ol>\n<li>40 个标准图片统一缩小成 8 x 8 并生成对应的图片哈希</li>\n<li>切割出的文字图片统一缩小成 8 x 8 并生成对应的图片哈希</li>\n<li>切割出文字哈希逐个与 40 个标准图片哈希比较，挑选出差异（相似度最高的）最小就是目标字母</li>\n</ol>\n<p>代码实现也比较简单：</p>\n<pre><code class=\"language-JavaScript\">async function createImageFingerprints(image) {\n    const contents = splitImage(image);\n    return contents.map(({ canvas, ...args }) =&gt; {\n        // 统一缩小到 8 像素\n        const imageData = resizeCanvas(canvas, 8);\n        const hash = binaryzationOutput(imageData);\n        return {\n            ...args,\n            hash,\n        };\n    });\n}\n\n// 生成标准字符指纹\nfunction createSymbols(fingerprints) {\n    const WORDS = 'abcdefghijklmnopqrstuvwxyz0123456789.-!?';\n    return fingerprints.map((it, index) =&gt; {\n        return {\n            name: WORDS[index],\n            value: it.hash,\n        };\n    });\n}\n\n// 匹配出最相似的字符\nfunction mapSymbols(fingerprints, symbols) {\n    return fingerprints.map(({ hash, ...position }) =&gt; {\n        const isEmpty = hash.every((v:) =&gt; v === hash[0]);\n        if (isEmpty) {\n            return ' ';\n        }\n        let diff = Number.MAX_SAFE_INTEGER;\n        let word = '*';\n        symbols.forEach((symbol) =&gt; {\n            const distance = hammingDistance(hash, symbol.value);\n            // 汉明距离大于标识相似度偏差较大排除\n            if (distance &lt; diff) {\n                diff = distance;\n                word = symbol.name;\n            }\n        });\n        return {\n            ...position,\n            word,\n            diff,\n        };\n    });\n}\n</code></pre>\n<p>使用大概是这样的：</p>\n<pre><code class=\"language-JavaScript\">/** \n * @param imageUrl 解析的图片\n * @param mapUrl 标准字符图片\n*/\nexport async function readMetaInfo(imageUrl, mapUrl) {\n    const mapImage = await loadImage(mapUrl);\n    const mapImageFingerprints = await createImageFingerprints(mapImage, false);\n    const symbols = createSymbols(mapImageFingerprints);\n    const readImage = await loadImage(imageUrl);\n    const readImageFingerprints = await createImageFingerprints(\n        readImage,\n        true\n    );\n    const results = mapSymbols(readImageFingerprints, symbols);\n    console.log(results);\n}\n</code></pre>\n<p><a href=\"https://github.com/kinglisky/zelda-words/blob/master/src/utils/image-ocr.ts#L390\" rel=\"nofollow\">完整代码实现可以戳这里</a>，至此一个简简简单版的希卡文 OCR 翻译器就完成了~</p>\n<h2>其他</h2>\n<ul>\n<li><a href=\"https://juejin.cn/post/6935836863844319239/\" rel=\"nofollow\">摸一个塞尔达希卡文字转换器</a></li>\n<li><a href=\"https://juejin.cn/post/6926181310868226061\" rel=\"nofollow\">相似图片识别的朴素实现</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000021236326\" rel=\"nofollow\">利用 JS 实现多种图片相似度算法</a></li>\n<li><a href=\"https://blog.csdn.net/Print_lin/article/details/80143002?spm=1001.2014.3001.5501\" rel=\"nofollow\">文字切割算法-基于投影的切割</a></li>\n<li><a href=\"https://blog.csdn.net/Print_lin/article/details/80335236\" rel=\"nofollow\">文字切割算法-投影切割优化</a></li>\n</ul>\n<p>摸鱼做的一个小东西，粗略的了解了下 OCR 的实现还是很开心的。</p>\n", "last_modified": 1616119370, "replies": 41, "id": 763083}]