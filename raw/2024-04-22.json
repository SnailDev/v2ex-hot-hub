[{"node": {"avatar_large": "https://cdn.v2ex.com/navatar/38af/8613/176_large.png?m=1644885960", "name": "car", "avatar_normal": "https://cdn.v2ex.com/navatar/38af/8613/176_normal.png?m=1644885960", "title": "汽车", "url": "https://www.v2ex.com/go/car", "topics": 2085, "footer": "", "header": "关于买车、开车及汽车文化的技术讨论", "title_alternative": "Car", "avatar_mini": "https://cdn.v2ex.com/navatar/38af/8613/176_mini.png?m=1644885960", "stars": 1833, "aliases": [], "root": false, "id": 176, "parent_node_name": "life"}, "member": {"id": 649817, "username": "haha922", "url": "https://www.v2ex.com/u/haha922", "website": "", "twitter": null, "psn": null, "github": null, "btc": null, "location": "", "tagline": "", "bio": "", "avatar_mini": "https://cdn.v2ex.com/avatar/1919/7b03/649817_mini.png?m=1702996268", "avatar_normal": "https://cdn.v2ex.com/avatar/1919/7b03/649817_normal.png?m=1702996268", "avatar_large": "https://cdn.v2ex.com/avatar/1919/7b03/649817_large.png?m=1702996268", "avatar_xlarge": "https://cdn.v2ex.com/avatar/1919/7b03/649817_xlarge.png?m=1702996268", "avatar_xxlarge": "https://cdn.v2ex.com/avatar/1919/7b03/649817_xlarge.png?m=1702996268", "avatar_xxxlarge": "https://cdn.v2ex.com/avatar/1919/7b03/649817_xlarge.png?m=1702996268", "created": 1695363501, "last_modified": 1702996268}, "last_reply_by": "likai", "last_touched": 1713758322, "title": "为什么那么多人吐槽日系车？我吐槽的只是日系车主开的慢", "url": "https://www.v2ex.com/t/1034465", "created": 1713743624, "deleted": 0, "content": "经常看到吐槽日系车的帖子，现在日系也很便宜了，为啥还在吐槽？马云早就不是首富了，那些吐槽马云的也没看登上富豪榜啊？\r\n那些吹爆国产的都买过几辆国产？买过几辆日系才有必要吐槽日系？不会连驾照都没有吧？\r\n我开过日系三大妈，同价位来说太棒了。作为国产车主，以后会换日系。", "content_rendered": "经常看到吐槽日系车的帖子，现在日系也很便宜了，为啥还在吐槽？马云早就不是首富了，那些吐槽马云的也没看登上富豪榜啊？<br />那些吹爆国产的都买过几辆国产？买过几辆日系才有必要吐槽日系？不会连驾照都没有吧？<br />我开过日系三大妈，同价位来说太棒了。作为国产车主，以后会换日系。", "last_modified": 1713747568, "replies": 119, "id": 1034465}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_large.png?m=1650095340", "name": "qna", "avatar_normal": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_normal.png?m=1650095340", "title": "问与答", "url": "https://www.v2ex.com/go/qna", "topics": 218084, "footer": "", "header": "一个更好的世界需要你持续地提出好问题。", "title_alternative": "Questions and Answers", "avatar_mini": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_mini.png?m=1650095340", "stars": 4148, "aliases": [], "root": false, "id": 12, "parent_node_name": "v2ex"}, "member": {"id": 493197, "username": "Liftman", "url": "https://www.v2ex.com/u/Liftman", "website": null, "twitter": null, "psn": null, "github": null, "btc": null, "location": null, "tagline": null, "bio": null, "avatar_mini": "https://cdn.v2ex.com/avatar/ee4a/3666/493197_mini.png?m=1703416189", "avatar_normal": "https://cdn.v2ex.com/avatar/ee4a/3666/493197_normal.png?m=1703416189", "avatar_large": "https://cdn.v2ex.com/avatar/ee4a/3666/493197_large.png?m=1703416189", "avatar_xlarge": "https://cdn.v2ex.com/avatar/ee4a/3666/493197_xlarge.png?m=1703416189", "avatar_xxlarge": "https://cdn.v2ex.com/avatar/ee4a/3666/493197_xlarge.png?m=1703416189", "avatar_xxxlarge": "https://cdn.v2ex.com/avatar/ee4a/3666/493197_xlarge.png?m=1703416189", "created": 1591261248, "last_modified": 1703416189}, "last_reply_by": "lokya", "last_touched": 1713758307, "title": "有什么室内养老爱好可以推荐的吗？", "url": "https://www.v2ex.com/t/1034413", "created": 1713702781, "deleted": 0, "content": "这两年生活和物质极度稳定，也没有结婚之类的负能量需求。基本上休闲的时间基本上就是。养鱼，玩玩块根，最近开始入门盆景了。\r\n\r\n而且感觉现在植物越买越多。最近半年买了一连排的植物。都已经开始考虑租个地了。正经的当成爱好培养了。毕竟写字楼里面的环境真不合适。\r\n\r\n但是植物和养鱼大部分时间是不需要参与的。所以还有什么适合年龄大的“室内”爱好吗。", "content_rendered": "<p>这两年生活和物质极度稳定，也没有结婚之类的负能量需求。基本上休闲的时间基本上就是。养鱼，玩玩块根，最近开始入门盆景了。</p>\n<p>而且感觉现在植物越买越多。最近半年买了一连排的植物。都已经开始考虑租个地了。正经的当成爱好培养了。毕竟写字楼里面的环境真不合适。</p>\n<p>但是植物和养鱼大部分时间是不需要参与的。所以还有什么适合年龄大的“室内”爱好吗。</p>\n", "last_modified": 1713702781, "replies": 79, "id": 1034413}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_large.png?m=1650095340", "name": "qna", "avatar_normal": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_normal.png?m=1650095340", "title": "问与答", "url": "https://www.v2ex.com/go/qna", "topics": 218084, "footer": "", "header": "一个更好的世界需要你持续地提出好问题。", "title_alternative": "Questions and Answers", "avatar_mini": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_mini.png?m=1650095340", "stars": 4148, "aliases": [], "root": false, "id": 12, "parent_node_name": "v2ex"}, "member": {"id": 355215, "username": "hhhsuan", "url": "https://www.v2ex.com/u/hhhsuan", "website": "", "twitter": "", "psn": "", "github": "", "btc": "", "location": "", "tagline": "", "bio": "", "avatar_mini": "https://cdn.v2ex.com/gravatar/4f51332978065b60ce4b17fbd178290b?s=24&d=retro", "avatar_normal": "https://cdn.v2ex.com/gravatar/4f51332978065b60ce4b17fbd178290b?s=48&d=retro", "avatar_large": "https://cdn.v2ex.com/gravatar/4f51332978065b60ce4b17fbd178290b?s=73&d=retro", "created": 1539225780, "last_modified": 1539225780}, "last_reply_by": "tianshilei1992", "last_touched": 1713758881, "title": "求推荐适合下雨天穿的鞋", "url": "https://www.v2ex.com/t/1034478", "created": 1713748478, "deleted": 0, "content": "要能够防水，防滑，轻便，休闲，之前在 tb 买了一双号称防水的运动鞋，结果根本没用，雨稍微大点鞋里一样湿", "content_rendered": "<p>要能够防水，防滑，轻便，休闲，之前在 tb 买了一双号称防水的运动鞋，结果根本没用，雨稍微大点鞋里一样湿</p>\n", "last_modified": 1713748478, "replies": 72, "id": 1034478}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/a3c6/5c29/108_large.png?m=1691642161", "name": "bb", "avatar_normal": "https://cdn.v2ex.com/navatar/a3c6/5c29/108_normal.png?m=1691642161", "title": "宽带症候群", "url": "https://www.v2ex.com/go/bb", "topics": 15256, "footer": "", "header": "网速很重要。比快更快。", "title_alternative": "Broadband Symptom Complex", "avatar_mini": "https://cdn.v2ex.com/navatar/a3c6/5c29/108_mini.png?m=1691642161", "stars": 7311, "aliases": [], "root": false, "id": 108, "parent_node_name": "geek"}, "member": {"id": 551037, "username": "RageBubble", "url": "https://www.v2ex.com/u/RageBubble", "website": "", "twitter": null, "psn": null, "github": null, "btc": null, "location": "", "tagline": "", "bio": "", "avatar_mini": "https://cdn.v2ex.com/avatar/3426/d183/551037_mini.png?m=1713672543", "avatar_normal": "https://cdn.v2ex.com/avatar/3426/d183/551037_normal.png?m=1713672543", "avatar_large": "https://cdn.v2ex.com/avatar/3426/d183/551037_large.png?m=1713672543", "avatar_xlarge": "https://cdn.v2ex.com/avatar/3426/d183/551037_xlarge.png?m=1713672543", "avatar_xxlarge": "https://cdn.v2ex.com/avatar/3426/d183/551037_xlarge.png?m=1713672543", "avatar_xxxlarge": "https://cdn.v2ex.com/avatar/3426/d183/551037_xlarge.png?m=1713672543", "created": 1626416739, "last_modified": 1713672543}, "last_reply_by": "isukkaw", "last_touched": 1713742764, "title": "使用 clash 上网时应对 dns 泄露的心得", "url": "https://www.v2ex.com/t/1034325", "created": 1713672957, "deleted": 0, "content": "** 本人使用的是 clash verge rev 客户端，内核为 clash-meta （ mihomo ），windows 系统。\r\n\r\n# 一、\r\n\r\n最近我对上网隐私有些关注，虽然 vpn 可以有效保护隐私，但根据大家都知道的原因，vpn 上网在国内非常不方便，一个是无法根据域名和 ip 分流，另一个是 vpn 协议太容易被检测。所以我就在想，使用 clash 这类更符合国情的代理软件，怎么才能保证基本的隐私和信息安全呢？\r\n\r\n当然我只是追求基本的隐私保护，对于更高的安全需求，当然可以使用 tor 网络和虚拟机等，这些不在此次讨论范围，我主要以 ipleak.net 这类网站的结果作为判断标准。\r\n\r\nipleak.net 这类网站对泄露的检测可以分为三类：dns 泄露，ip 泄露，webrtc 泄露。\r\n\r\n只要使用 clash 上网，ip 泄露和 webrtc 泄露检测的结果都是代理服务器的 ip ，这两个没什么问题。但是对于 dns 泄露，我总是发现检测到的服务器列表里，除了国外的服务器，竟然还有很多是国内的 dns 服务器（包括本地 isp 运营商的），而在我的 clash 中（系统代理+规则模式），dns 字段里 nameserver 设置的是 8.8.8.8 ，fallback 设置的是国外加密 dns 。这有些不对劲，因国内的 dns 服务器不应该出现。\r\n\r\n这里说明一下，clash 的 dns 字段里，nameserver 就是主要使用的 dns 服务器，default-nameserver 是用来解析 nameserver 中的加密 dns （如果有加密 dns 的话），fallback 是备用的 dns 服务器，当 clash 要发出 dns 请求时，如果 fallback-filter 没有特别设置，会并发的向 nameserver 和 fallback 中的 dns 服务器发出解析请求，使用最早响应的那个结果。\r\n\r\n![mihomo 的 dns 解析流程]( https://i.imgur.com/OB9ER5A.png)\r\n\r\n言归正传，为了搞清楚这背后的原理，我做了很多测试，用到了 wireshark 抓包 53 端口的 dns 请求。发现 wireshark 中，电脑是按照 clash 配置正确地，并发地向 nameserver 和 fallback 中的 dns 服务器发出了域名解析请求（ ipleak 提供的测试域名），也收到了发回的响应，所以不太可能是 clash 或者 windows 系统的问题。\r\n\r\n我推测会不会是因为 nameserver 使用了明文 dns ，导致 dns 泄露，使得 isp 运营商的 dns 服务器也向测试域名发出了解析请求。于是我把配置里 nameserver 中的 dns 服务器全部替换成加密 dns （ DOH ），果然，再次检测后就再也没有中国 dns 服务器的踪迹了。\r\n\r\n需要说明的是，当 clash 使用系统代理+全局模式时，dns 请求会被 clash 加密并全部发往代理服务器，是让代理服务器的 dns 去解析域名，所以也不会出现国内 dns 服务器的踪迹。\r\n\r\n# 二、\r\n\r\n在解决了上面的 dns 泄露问题后，我又有了新的疑惑。\r\n\r\nclash 系统代理下的规则模式打开，通过 ipleak 网站测试，我发现明明 clash 日志中这些 ipleak 的测试域名最后都是命中了我规则中最后一行的 final （ final 的作用是兜底，当前面的所有规则都没有命中时，域名最后会命中 final 规则，我设置的是命中 final 规则后使用代理服务器）.本应该是通过代理服务器去解析域名，但得到的结果和全局模式下检测到的 dns 服务器不同，而且 wireshark 中会发现 clash 在通过 nameserver 和 fallback 发送域名解析请求.\r\n\r\n因为根据那张流程图，域名命中代理规则后应该直接让代理服务器去解析域名，电脑上的 clash 是不该发出这些请求的。这是为什么呢？原因只能是这些测试域名既通过了代理服务器解析域名，又通过 clash 的 dns 去解析域名。\r\n\r\n我又折腾了一下，到处上网查阅，仔细查看那张 dns 解析流程图，我注意到了“匹配到基于 ip 的规则”这几个字，瞬间恍然大悟。原来这是因为 clash 通过从上往下的方式一条条匹配规则，直到命中规则停止。这些测试域名的确命中了 final 规则，通过代理服务器的 dns 解析了域名。\r\n\r\n但是，在此之前，由于我的配置中有基于 ip 的规则存在，位置比 final 规则更靠前，并且没有加上 no- resolve 这个参数（ no-resolve 告诉 clash 在遇到基于 ip 的规则时，不要去单独解析域名），导致在遇到这些靠前的 ip 规则时，clash 会先通过 nameserver 和 fallback 中的服务器并发请求，以查看该域名是否符合该 ip 规则，不符合则继续往下匹配规则，最后命中了 final 规则。\r\n\r\n所以这就是为什么在我的电脑上，这些 ipleak 的测试域名既会先被 clash 上的 dns 解析，还会被代理服务器上的 dns 解析。而在全局模式下，因为不需要判断规则，这些自定义测试域名只会被代理服务器解析。\r\n\r\n# 三、\r\n\r\n说了这么多，我总结出来的经验是，要想避免 dns 泄漏，一个方法是在 nameserver 中使用加密 dns ，另一个是给配置中的 ip 规则后面加上 no- resolve ，告诉 clash 直接跳过，不要去解析域名。最后是 fallback-filter 中设置 geosite 为“!CN”等，这样在遇到国外的网站域名时，clash 不会再并发请求，只会使用 fallback 的 dns 服务器而不会使用 nameserver 中的服务器。可以看出，最后两个方法的思路都是不让 clash 向 nameserver 发送国外网站的 dns 请求。为了防止 dns 泄露，这三个方法我建议最好同时使用。\r\n\r\n上面就是最近这段时间我自己折腾后整理出来的心得，希望能帮助知道如何处理出现的 dns 泄露。不知道文中有没有什么错误，欢迎大家反馈。另外，我到现在也不太清楚图片中的 fake-ip 未命中和 fakeip-Direct 未命中是什么意思，该如何理解，希望有大佬解释一下。", "content_rendered": "<p>** 本人使用的是 clash verge rev 客户端，内核为 clash-meta （ mihomo ），windows 系统。</p>\n<h1>一、</h1>\n<p>最近我对上网隐私有些关注，虽然 vpn 可以有效保护隐私，但根据大家都知道的原因，vpn 上网在国内非常不方便，一个是无法根据域名和 ip 分流，另一个是 vpn 协议太容易被检测。所以我就在想，使用 clash 这类更符合国情的代理软件，怎么才能保证基本的隐私和信息安全呢？</p>\n<p>当然我只是追求基本的隐私保护，对于更高的安全需求，当然可以使用 tor 网络和虚拟机等，这些不在此次讨论范围，我主要以 <a href=\"http://ipleak.net\" rel=\"nofollow\">ipleak.net</a> 这类网站的结果作为判断标准。</p>\n<p><a href=\"http://ipleak.net\" rel=\"nofollow\">ipleak.net</a> 这类网站对泄露的检测可以分为三类：dns 泄露，ip 泄露，webrtc 泄露。</p>\n<p>只要使用 clash 上网，ip 泄露和 webrtc 泄露检测的结果都是代理服务器的 ip ，这两个没什么问题。但是对于 dns 泄露，我总是发现检测到的服务器列表里，除了国外的服务器，竟然还有很多是国内的 dns 服务器（包括本地 isp 运营商的），而在我的 clash 中（系统代理+规则模式），dns 字段里 nameserver 设置的是 8.8.8.8 ，fallback 设置的是国外加密 dns 。这有些不对劲，因国内的 dns 服务器不应该出现。</p>\n<p>这里说明一下，clash 的 dns 字段里，nameserver 就是主要使用的 dns 服务器，default-nameserver 是用来解析 nameserver 中的加密 dns （如果有加密 dns 的话），fallback 是备用的 dns 服务器，当 clash 要发出 dns 请求时，如果 fallback-filter 没有特别设置，会并发的向 nameserver 和 fallback 中的 dns 服务器发出解析请求，使用最早响应的那个结果。</p>\n<p><img alt=\"mihomo 的 dns 解析流程\" class=\"embedded_image\" loading=\"lazy\" referrerpolicy=\"no-referrer\" rel=\"noreferrer\" src=\"https://i.imgur.com/OB9ER5A.png\"/></p>\n<p>言归正传，为了搞清楚这背后的原理，我做了很多测试，用到了 wireshark 抓包 53 端口的 dns 请求。发现 wireshark 中，电脑是按照 clash 配置正确地，并发地向 nameserver 和 fallback 中的 dns 服务器发出了域名解析请求（ ipleak 提供的测试域名），也收到了发回的响应，所以不太可能是 clash 或者 windows 系统的问题。</p>\n<p>我推测会不会是因为 nameserver 使用了明文 dns ，导致 dns 泄露，使得 isp 运营商的 dns 服务器也向测试域名发出了解析请求。于是我把配置里 nameserver 中的 dns 服务器全部替换成加密 dns （ DOH ），果然，再次检测后就再也没有中国 dns 服务器的踪迹了。</p>\n<p>需要说明的是，当 clash 使用系统代理+全局模式时，dns 请求会被 clash 加密并全部发往代理服务器，是让代理服务器的 dns 去解析域名，所以也不会出现国内 dns 服务器的踪迹。</p>\n<h1>二、</h1>\n<p>在解决了上面的 dns 泄露问题后，我又有了新的疑惑。</p>\n<p>clash 系统代理下的规则模式打开，通过 ipleak 网站测试，我发现明明 clash 日志中这些 ipleak 的测试域名最后都是命中了我规则中最后一行的 final （ final 的作用是兜底，当前面的所有规则都没有命中时，域名最后会命中 final 规则，我设置的是命中 final 规则后使用代理服务器）.本应该是通过代理服务器去解析域名，但得到的结果和全局模式下检测到的 dns 服务器不同，而且 wireshark 中会发现 clash 在通过 nameserver 和 fallback 发送域名解析请求.</p>\n<p>因为根据那张流程图，域名命中代理规则后应该直接让代理服务器去解析域名，电脑上的 clash 是不该发出这些请求的。这是为什么呢？原因只能是这些测试域名既通过了代理服务器解析域名，又通过 clash 的 dns 去解析域名。</p>\n<p>我又折腾了一下，到处上网查阅，仔细查看那张 dns 解析流程图，我注意到了“匹配到基于 ip 的规则”这几个字，瞬间恍然大悟。原来这是因为 clash 通过从上往下的方式一条条匹配规则，直到命中规则停止。这些测试域名的确命中了 final 规则，通过代理服务器的 dns 解析了域名。</p>\n<p>但是，在此之前，由于我的配置中有基于 ip 的规则存在，位置比 final 规则更靠前，并且没有加上 no- resolve 这个参数（ no-resolve 告诉 clash 在遇到基于 ip 的规则时，不要去单独解析域名），导致在遇到这些靠前的 ip 规则时，clash 会先通过 nameserver 和 fallback 中的服务器并发请求，以查看该域名是否符合该 ip 规则，不符合则继续往下匹配规则，最后命中了 final 规则。</p>\n<p>所以这就是为什么在我的电脑上，这些 ipleak 的测试域名既会先被 clash 上的 dns 解析，还会被代理服务器上的 dns 解析。而在全局模式下，因为不需要判断规则，这些自定义测试域名只会被代理服务器解析。</p>\n<h1>三、</h1>\n<p>说了这么多，我总结出来的经验是，要想避免 dns 泄漏，一个方法是在 nameserver 中使用加密 dns ，另一个是给配置中的 ip 规则后面加上 no- resolve ，告诉 clash 直接跳过，不要去解析域名。最后是 fallback-filter 中设置 geosite 为“!CN”等，这样在遇到国外的网站域名时，clash 不会再并发请求，只会使用 fallback 的 dns 服务器而不会使用 nameserver 中的服务器。可以看出，最后两个方法的思路都是不让 clash 向 nameserver 发送国外网站的 dns 请求。为了防止 dns 泄露，这三个方法我建议最好同时使用。</p>\n<p>上面就是最近这段时间我自己折腾后整理出来的心得，希望能帮助知道如何处理出现的 dns 泄露。不知道文中有没有什么错误，欢迎大家反馈。另外，我到现在也不太清楚图片中的 fake-ip 未命中和 fakeip-Direct 未命中是什么意思，该如何理解，希望有大佬解释一下。</p>\n", "last_modified": 1713678801, "replies": 63, "id": 1034325}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/fc22/1309/181_large.png?m=1608240651", "name": "travel", "avatar_normal": "https://cdn.v2ex.com/navatar/fc22/1309/181_normal.png?m=1608240651", "title": "旅行", "url": "https://www.v2ex.com/go/travel", "topics": 1036, "footer": "", "header": "你会把上大学的学费用来环游世界么？", "title_alternative": "Travel", "avatar_mini": "https://cdn.v2ex.com/navatar/fc22/1309/181_mini.png?m=1608240651", "stars": 1042, "aliases": [], "root": false, "id": 181, "parent_node_name": "life"}, "member": {"id": 328194, "username": "37Y37", "url": "https://www.v2ex.com/u/37Y37", "website": "https://blog.ops-coffee.cn", "twitter": "", "psn": "", "github": "", "btc": "", "location": "", "tagline": "", "bio": "", "avatar_mini": "https://cdn.v2ex.com/gravatar/e80130f0e891c74c0757e084e2854259?s=24&d=retro", "avatar_normal": "https://cdn.v2ex.com/gravatar/e80130f0e891c74c0757e084e2854259?s=48&d=retro", "avatar_large": "https://cdn.v2ex.com/gravatar/e80130f0e891c74c0757e084e2854259?s=73&d=retro", "created": 1531206003, "last_modified": 1643689570}, "last_reply_by": "37Y37", "last_touched": 1713758244, "title": "五一马上到了，几个我去过的人少景美的地方可以参考", "url": "https://www.v2ex.com/t/1034493", "created": 1713750585, "deleted": 0, "content": "最近三年的五一自驾路线，给大伙做个参考：\r\n\r\n1. [环千岛湖自驾]( https://blog.ops-coffee.cn/s/lJawB7Yb5O11qczx9aeqRQ.html)，节假日去千岛湖的很多，但很少有去环湖自驾的，所以人不是特别多，风景也不错\r\n2. [皖浙一号公路]( https://blog.ops-coffee.cn/s/omDL4c08_M1oyuR_GSjOLw.html)，千岛湖一段也算是皖浙一号公路一部分，从浙江到皖南，浙江段都很漂亮，安徽段新安江段是精华，这条路线相对小众，我 2021 年五一去自驾的，几乎没人\r\n3. [环太湖自驾]( https://blog.ops-coffee.cn/s/YKLL0IhDnE3u9K79D1UYqw.html)，一路沿着太湖在驾驶，风景/感觉都不错，这两年环太湖自驾也逐渐有了热度，建设配套也都十分成熟了\r\n4. [浙西天路自驾]( https://blog.ops-coffee.cn/r/hualangxian-huihanggudao-zhexitianlu.html)，浙西第一高峰太子尖，山峦叠嶂，跟看到的浙江境内大部分山峰都不太一样，经过徽杭古道，对徒步感兴趣的也可以去徽杭古道徒步\r\n5. [溧阳彩虹公路]( https://blog.ops-coffee.cn/r/city-china-jiangsu-changzhou-liyang-yihaogonglu-01.html)，溧阳境内的彩虹公路总长有 365 公里，沿途经过很多村镇，风景都还不错，只要不是热门的打卡点，人也不是很多\r\n\r\n还有其他一些线路，太热门了，就不推荐五一自驾了，例如：[皖南 318]( https://blog.ops-coffee.cn/r/wannan-318-chuanzangxian-taipinghu.html)每到节假日都堵车，[四明山自驾]( https://blog.ops-coffee.cn/s/HApDTE3c0o4YL5ntx0Aa1Q.html)也不错，不过应该车也很多，容易堵车。就不推荐城市出行了吧，江浙沪所有的城市有一个算一个人都超级多，尤其是那这能叫出来名字的城市：苏州杭州南京等等人多到爆炸，注重旅行体验的尽量避开\r\n\r\n对于不同旅行形式，自驾旅行群体毕竟小很多，所以不是特别热门的路线，路上人都不会特别多\r\n\r\n最后想问问喜欢自驾的大伙五一准备去哪？发一下，我做个参考，毕竟到现在，我还没确定五一去哪呢，不过确定的是一定会出去，继续自驾", "content_rendered": "<p>最近三年的五一自驾路线，给大伙做个参考：</p>\n<ol>\n<li><a href=\"https://blog.ops-coffee.cn/s/lJawB7Yb5O11qczx9aeqRQ.html\" rel=\"nofollow\">环千岛湖自驾</a>，节假日去千岛湖的很多，但很少有去环湖自驾的，所以人不是特别多，风景也不错</li>\n<li><a href=\"https://blog.ops-coffee.cn/s/omDL4c08_M1oyuR_GSjOLw.html\" rel=\"nofollow\">皖浙一号公路</a>，千岛湖一段也算是皖浙一号公路一部分，从浙江到皖南，浙江段都很漂亮，安徽段新安江段是精华，这条路线相对小众，我 2021 年五一去自驾的，几乎没人</li>\n<li><a href=\"https://blog.ops-coffee.cn/s/YKLL0IhDnE3u9K79D1UYqw.html\" rel=\"nofollow\">环太湖自驾</a>，一路沿着太湖在驾驶，风景/感觉都不错，这两年环太湖自驾也逐渐有了热度，建设配套也都十分成熟了</li>\n<li><a href=\"https://blog.ops-coffee.cn/r/hualangxian-huihanggudao-zhexitianlu.html\" rel=\"nofollow\">浙西天路自驾</a>，浙西第一高峰太子尖，山峦叠嶂，跟看到的浙江境内大部分山峰都不太一样，经过徽杭古道，对徒步感兴趣的也可以去徽杭古道徒步</li>\n<li><a href=\"https://blog.ops-coffee.cn/r/city-china-jiangsu-changzhou-liyang-yihaogonglu-01.html\" rel=\"nofollow\">溧阳彩虹公路</a>，溧阳境内的彩虹公路总长有 365 公里，沿途经过很多村镇，风景都还不错，只要不是热门的打卡点，人也不是很多</li>\n</ol>\n<p>还有其他一些线路，太热门了，就不推荐五一自驾了，例如：<a href=\"https://blog.ops-coffee.cn/r/wannan-318-chuanzangxian-taipinghu.html\" rel=\"nofollow\">皖南 318</a>每到节假日都堵车，<a href=\"https://blog.ops-coffee.cn/s/HApDTE3c0o4YL5ntx0Aa1Q.html\" rel=\"nofollow\">四明山自驾</a>也不错，不过应该车也很多，容易堵车。就不推荐城市出行了吧，江浙沪所有的城市有一个算一个人都超级多，尤其是那这能叫出来名字的城市：苏州杭州南京等等人多到爆炸，注重旅行体验的尽量避开</p>\n<p>对于不同旅行形式，自驾旅行群体毕竟小很多，所以不是特别热门的路线，路上人都不会特别多</p>\n<p>最后想问问喜欢自驾的大伙五一准备去哪？发一下，我做个参考，毕竟到现在，我还没确定五一去哪呢，不过确定的是一定会出去，继续自驾</p>\n", "last_modified": 1713750585, "replies": 52, "id": 1034493}, {"node": {"avatar_large": "/static/img/node_default_large.png", "name": "fit", "avatar_normal": "/static/img/node_default_normal.png", "title": "健康", "url": "https://www.v2ex.com/go/fit", "topics": 1143, "footer": "", "header": "这个节点的设立，是为了让大家可以分享关于健身和健康生活方式的经验。如果你有什么正在困扰自己的身体症状，请立刻寻求正规医院的帮助。", "title_alternative": "Fit", "avatar_mini": "/static/img/node_default_mini.png", "stars": 330, "aliases": [], "root": false, "id": 700, "parent_node_name": "life"}, "member": {"id": 647341, "username": "lambdaX999", "url": "https://www.v2ex.com/u/lambdaX999", "website": null, "twitter": null, "psn": null, "github": null, "btc": null, "location": null, "tagline": null, "bio": null, "avatar_mini": "https://cdn.v2ex.com/gravatar/38dd1eee72b678145adce36c8613ad16?s=24&d=retro", "avatar_normal": "https://cdn.v2ex.com/gravatar/38dd1eee72b678145adce36c8613ad16?s=48&d=retro", "avatar_large": "https://cdn.v2ex.com/gravatar/38dd1eee72b678145adce36c8613ad16?s=73&d=retro", "created": 1693986139, "last_modified": 1693986139}, "last_reply_by": "twofox", "last_touched": 1713757869, "title": "有没有二阳/三阳/多阳的 V 友交流下症状啊", "url": "https://www.v2ex.com/t/1034481", "created": 1713748963, "deleted": 0, "content": "RT\r\n上周五、周六的时候浑身肌肉酸痛，腰酸，浑身无力，躺了两天基本上好了，然后昨天晚上开始头部剧痛，一度以为是要脑溢血了，晚上吃了必理痛稍微好点，但是一晚上基本上没睡好，早上起来还是微微痛。\r\n\r\n在一些兄弟群交流了，也有跟我这个症状一样的，就是不知道是不是阳了，这种情况要不要去医院查下，要查的话这玩儿算啥科啊", "content_rendered": "<p>RT\n上周五、周六的时候浑身肌肉酸痛，腰酸，浑身无力，躺了两天基本上好了，然后昨天晚上开始头部剧痛，一度以为是要脑溢血了，晚上吃了必理痛稍微好点，但是一晚上基本上没睡好，早上起来还是微微痛。</p>\n<p>在一些兄弟群交流了，也有跟我这个症状一样的，就是不知道是不是阳了，这种情况要不要去医院查下，要查的话这玩儿算啥科啊</p>\n", "last_modified": 1713757966, "replies": 47, "id": 1034481}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/4ea0/6fbc/770_large.png?m=1695370146", "name": "career", "avatar_normal": "https://cdn.v2ex.com/navatar/4ea0/6fbc/770_normal.png?m=1695370146", "title": "职场话题", "url": "https://www.v2ex.com/go/career", "topics": 16839, "footer": "", "header": "这里，我们聊聊那些工作中遇到的开心和不开心的事。", "title_alternative": "Career", "avatar_mini": "https://cdn.v2ex.com/navatar/4ea0/6fbc/770_mini.png?m=1695370146", "stars": 3094, "aliases": [], "root": false, "id": 770, "parent_node_name": "work"}, "member": {"id": 661700, "username": "kutius67", "url": "https://www.v2ex.com/u/kutius67", "website": null, "twitter": null, "psn": null, "github": null, "btc": null, "location": null, "tagline": null, "bio": null, "avatar_mini": "https://cdn.v2ex.com/gravatar/8aae10d455f2eb7ea97668930afc98e5?s=24&d=retro", "avatar_normal": "https://cdn.v2ex.com/gravatar/8aae10d455f2eb7ea97668930afc98e5?s=48&d=retro", "avatar_large": "https://cdn.v2ex.com/gravatar/8aae10d455f2eb7ea97668930afc98e5?s=73&d=retro", "created": 1699627761, "last_modified": 1699627761}, "last_reply_by": "codywu", "last_touched": 1713755055, "title": "兄弟们帮我看一下拿到的一个国外全职远程是不是坑？", "url": "https://www.v2ex.com/t/1034371", "created": 1713689038, "deleted": 0, "content": "之前在 v 站看到有个国外远程前端招人，投了之后有一个多月的时间没有动静，后来 hr 突然联系我面试，我抱着试试的心态去面了，一面技术面，然后没后文，过了十天左右和我说一面过了，后面流程就是，直接他所称的技术部门领导谈入职时间和薪资（竟然只有一面？），到了这时候我才知道工资竟然是以 usdt 结算，hr 说公司在英国，项目内容是游戏门户平台网站，技术大多都在国内远程，其他在英国现场办公\r\n\r\n现在我比较担心的公司会不会是做灰色产业，以及会不会很不稳定，随时把人开了，因为薪资尚可（国内一般水平但是对我来说是理想的范围）\r\nhr 跟我说的是非黑灰，英国纯游戏项目，正规产业\r\n我没什么经验，所以来向兄弟们问问意见", "content_rendered": "<p>之前在 v 站看到有个国外远程前端招人，投了之后有一个多月的时间没有动静，后来 hr 突然联系我面试，我抱着试试的心态去面了，一面技术面，然后没后文，过了十天左右和我说一面过了，后面流程就是，直接他所称的技术部门领导谈入职时间和薪资（竟然只有一面？），到了这时候我才知道工资竟然是以 usdt 结算，hr 说公司在英国，项目内容是游戏门户平台网站，技术大多都在国内远程，其他在英国现场办公</p>\n<p>现在我比较担心的公司会不会是做灰色产业，以及会不会很不稳定，随时把人开了，因为薪资尚可（国内一般水平但是对我来说是理想的范围）\nhr 跟我说的是非黑灰，英国纯游戏项目，正规产业\n我没什么经验，所以来向兄弟们问问意见</p>\n", "last_modified": 1713689320, "replies": 46, "id": 1034371}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_large.png?m=1650095340", "name": "qna", "avatar_normal": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_normal.png?m=1650095340", "title": "问与答", "url": "https://www.v2ex.com/go/qna", "topics": 218084, "footer": "", "header": "一个更好的世界需要你持续地提出好问题。", "title_alternative": "Questions and Answers", "avatar_mini": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_mini.png?m=1650095340", "stars": 4148, "aliases": [], "root": false, "id": 12, "parent_node_name": "v2ex"}, "member": {"id": 516768, "username": "mijazz", "url": "https://www.v2ex.com/u/mijazz", "website": "", "twitter": "", "psn": "", "github": "", "btc": "", "location": "", "tagline": "", "bio": "", "avatar_mini": "https://cdn.v2ex.com/avatar/87c7/7c1c/516768_mini.png?m=1713749033", "avatar_normal": "https://cdn.v2ex.com/avatar/87c7/7c1c/516768_normal.png?m=1713749033", "avatar_large": "https://cdn.v2ex.com/avatar/87c7/7c1c/516768_large.png?m=1713749033", "avatar_xlarge": "https://cdn.v2ex.com/avatar/87c7/7c1c/516768_xlarge.png?m=1713749033", "avatar_xxlarge": "https://cdn.v2ex.com/avatar/87c7/7c1c/516768_xlarge.png?m=1713749033", "created": 1604987757, "last_modified": 1713749033}, "last_reply_by": "particlec", "last_touched": 1713758595, "title": "日常作为口粮的茶、咖啡等饮品终究还是会坠入口味越来越重的漩涡里？各位对于饮品的选择到哪一个阶段了呢？", "url": "https://www.v2ex.com/t/1034483", "created": 1713749184, "deleted": 0, "content": "两年之前在社区发了个帖子，请教各位 v2er 们日常都喝什么冻干咖啡。\r\n\r\n[/t/873897 - 各位有什么速溶或冻干黑咖啡推荐，作为工位口粮]( https://v2ex.com/t/873897#reply74)\r\n\r\n托各位的分享，我的口味已经从刚毕业时的 立顿茶包/雀巢咖啡 => 龙井茶/冻干黑咖啡 => 咖啡店的美式或者奶咖 => 浓普洱茶/澳白(FlatWhite +1 shot) 了。\r\n\r\n最近又扒拉上家里晒的陈皮和小青柑普洱，可谓是一去不复返，口味越来越重，又或者说口味越来越挑剔？有种人到中年就开始挑剔充电头参数和捣鼓 nas 保存照片的感觉。各位对于饮品的选择到哪一个阶段了呢？\r\n\r\n之前上一天班光买咖啡都得花个二三十，起码这回，泡陈皮和小青柑普洱不费钱了。作为新会陈皮原产区附近的家庭，这应该算花式啃老？😂 \r\n \r\nhttps://i.imgur.com/yBIXM7n.jpeg", "content_rendered": "<p>两年之前在社区发了个帖子，请教各位 v2er 们日常都喝什么冻干咖啡。</p>\n<p><a href=\"https://v2ex.com/t/873897#reply74\" rel=\"nofollow\">/t/873897 - 各位有什么速溶或冻干黑咖啡推荐，作为工位口粮</a></p>\n<p>托各位的分享，我的口味已经从刚毕业时的 立顿茶包/雀巢咖啡 =&gt; 龙井茶/冻干黑咖啡 =&gt; 咖啡店的美式或者奶咖 =&gt; 浓普洱茶/澳白(FlatWhite +1 shot) 了。</p>\n<p>最近又扒拉上家里晒的陈皮和小青柑普洱，可谓是一去不复返，口味越来越重，又或者说口味越来越挑剔？有种人到中年就开始挑剔充电头参数和捣鼓 nas 保存照片的感觉。各位对于饮品的选择到哪一个阶段了呢？</p>\n<p>之前上一天班光买咖啡都得花个二三十，起码这回，泡陈皮和小青柑普洱不费钱了。作为新会陈皮原产区附近的家庭，这应该算花式啃老？😂 </p>\n<p><a href=\"https://i.imgur.com/yBIXM7n.jpeg\" rel=\"nofollow\">https://i.imgur.com/yBIXM7n.jpeg</a></p>\n", "last_modified": 1713749184, "replies": 46, "id": 1034483}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_large.png?m=1650095340", "name": "qna", "avatar_normal": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_normal.png?m=1650095340", "title": "问与答", "url": "https://www.v2ex.com/go/qna", "topics": 218084, "footer": "", "header": "一个更好的世界需要你持续地提出好问题。", "title_alternative": "Questions and Answers", "avatar_mini": "https://cdn.v2ex.com/navatar/c20a/d4d7/12_mini.png?m=1650095340", "stars": 4148, "aliases": [], "root": false, "id": 12, "parent_node_name": "v2ex"}, "member": {"id": 662956, "username": "jkfadsljlasdgs", "url": "https://www.v2ex.com/u/jkfadsljlasdgs", "website": "", "twitter": null, "psn": null, "github": null, "btc": null, "location": "", "tagline": "", "bio": "", "avatar_mini": "https://cdn.v2ex.com/avatar/78ab/060a/662956_mini.png?m=1700469958", "avatar_normal": "https://cdn.v2ex.com/avatar/78ab/060a/662956_normal.png?m=1700469958", "avatar_large": "https://cdn.v2ex.com/avatar/78ab/060a/662956_large.png?m=1700469958", "avatar_xlarge": "https://cdn.v2ex.com/avatar/78ab/060a/662956_xlarge.png?m=1700469958", "avatar_xxlarge": "https://cdn.v2ex.com/avatar/78ab/060a/662956_xlarge.png?m=1700469958", "avatar_xxxlarge": "https://cdn.v2ex.com/avatar/78ab/060a/662956_xlarge.png?m=1700469958", "created": 1700134669, "last_modified": 1700469958}, "last_reply_by": "maxhuang", "last_touched": 1713758321, "title": "给家人用的（大流量，带通话）长期套餐的移动、联通手机卡推荐？", "url": "https://www.v2ex.com/t/1034468", "created": 1713746048, "deleted": 0, "content": "给家人用的，主要需求是：\r\n1 、大流量，也就是月 90g+\r\n2 、必须带通话，最低 100 ，最好是 200 或+\r\n3 、长期套餐，至少能用 2-3 年的\r\n4 、少操作折腾的，流量通话直给，不用比如还得找渠道返现充值，还得去 app 领流量、通话等等，家人不会操作\r\n5 、最好是本地归属地\r\n6 、预算 20 及以下", "content_rendered": "给家人用的，主要需求是：<br />1 、大流量，也就是月 90g+<br />2 、必须带通话，最低 100 ，最好是 200 或+<br />3 、长期套餐，至少能用 2-3 年的<br />4 、少操作折腾的，流量通话直给，不用比如还得找渠道返现充值，还得去 app 领流量、通话等等，家人不会操作<br />5 、最好是本地归属地<br />6 、预算 20 及以下", "last_modified": 1713746048, "replies": 44, "id": 1034468}, {"node": {"avatar_large": "https://cdn.v2ex.com/navatar/2421/fcb1/436_large.png?m=1650095204", "name": "nodejs", "avatar_normal": "https://cdn.v2ex.com/navatar/2421/fcb1/436_normal.png?m=1650095204", "title": "Node.js", "url": "https://www.v2ex.com/go/nodejs", "topics": 2475, "footer": "", "header": "Node.js is a platform built on <a href=\"http://code.google.com/p/v8/\" target=\"_blank\">Chrome's JavaScript runtime</a> for easily building fast, scalable network applications.", "title_alternative": "Node.js", "avatar_mini": "https://cdn.v2ex.com/navatar/2421/fcb1/436_mini.png?m=1650095204", "stars": 2885, "aliases": [], "root": false, "id": 436, "parent_node_name": "js"}, "member": {"id": 680753, "username": "coderhxl", "url": "https://www.v2ex.com/u/coderhxl", "website": null, "twitter": "", "psn": "", "github": "coder-hxl", "btc": "", "location": null, "tagline": null, "bio": null, "avatar_mini": "https://cdn.v2ex.com/gravatar/f8c420aee4ae2cf6716e6061ec39b09f?s=24&d=retro", "avatar_normal": "https://cdn.v2ex.com/gravatar/f8c420aee4ae2cf6716e6061ec39b09f?s=48&d=retro", "avatar_large": "https://cdn.v2ex.com/gravatar/f8c420aee4ae2cf6716e6061ec39b09f?s=73&d=retro", "created": 1710732966, "last_modified": 1713751639}, "last_reply_by": "coderhxl", "last_touched": 1713758426, "title": "传统爬虫 还是 AI 辅助爬虫？该怎么选？", "url": "https://www.v2ex.com/t/1034501", "created": 1713751667, "deleted": 0, "content": "## 前言\r\n\r\n在数据抓取领域，传统爬虫与 AI 辅助爬虫各有千秋。传统爬虫基于规则进行数据抓取，适用于结构稳定、规则明确的网站。然而，随着网站结构的频繁变动和复杂化，传统爬虫逐渐暴露出其局限性。相比之下，AI 辅助爬虫借助人工智能技术，能够智能解析网页、自适应变化，展现出更高的灵活性和准确性。那么，面对不同的抓取需求，我们该如何选择呢？本文将深入探讨传统爬虫与 AI 辅助爬虫的特点与优劣，为您提供决策参考。\r\n\r\n## 传统爬虫 和 AI 辅助爬虫 分别是什么\r\n\r\n### 传统爬虫\r\n\r\n传统爬虫主要依赖于固定的规则或模式来抓取网页数据。它们通常通过识别网页中的特定元素，如类名、标签或结构，来定位和提取所需信息。然而，这种方式的局限性显而易见。一旦网站进行更新，改变了原有的类名、标签或结构，传统爬虫就会因为无法识别新的元素而失效，导致数据抓取失败或错误。\r\n\r\n### AI 辅助爬虫\r\n\r\nAI 辅助爬虫能够智能地分析和理解网页内容，从而更准确地定位并提取所需信息。通过自然语言处理等技术，它们能够理解网页的语义信息，从而更精确地定位所需数据，即使网站进行了更新，AI 辅助爬虫也能继续有效地抓取数据。\r\n\r\n## 示例\r\n\r\n选用大家熟悉的豆瓣来进行示范，而爬虫则是用 [x-crawl]( https://github.com/coder-hxl/x-crawl) 。\r\n\r\n- 传统爬虫，通过网页中的特定元素获取豆瓣电影排行榜的电影信息\r\n- 爬虫 + AI ，爬虫搭配 AI 获取豆瓣电影排行榜的电影信息\r\n\r\n### 传统爬虫\r\n\r\n**传统爬虫，通过网页中的特定元素获取豆瓣电影排行榜的电影信息**\r\n\r\n```js\r\nimport { createCrawl } from 'x-crawl'\r\n\r\n// 创建爬虫应用\r\nconst crawlApp = createCrawl()\r\n\r\n// crawlPage 用于爬取页面\r\ncrawlApp.crawlPage('https://movie.douban.com/chart').then(async (res) => {\r\n  const { page, browser } = res.data\r\n\r\n  // 等待元素出现在页面中\r\n  await page.waitForSelector('#wrapper #content .article')\r\n  const filmHandleList = await page.$$('#wrapper #content .article table')\r\n\r\n  const pendingTask = []\r\n  for (const filmHandle of filmHandleList) {\r\n    // 封面链接(picture)\r\n    const picturePending = filmHandle.$eval('td img', (img) => img.src)\r\n    // 电影名(name)\r\n    const namePending = filmHandle.$eval(\r\n      'td:nth-child(2) a',\r\n      (el) => el.innerText.split(' / ')[0]\r\n    )\r\n    // 简介(info)\r\n    const infoPending = filmHandle.$eval(\r\n      'td:nth-child(2) .pl',\r\n      (el) => el.textContent\r\n    )\r\n    // 评分(score)\r\n    const scorePending = filmHandle.$eval(\r\n      'td:nth-child(2) .star .rating_nums',\r\n      (el) => el.textContent\r\n    )\r\n    // 评论人数(commentsNumber)\r\n    const commentsNumberPending = filmHandle.$eval(\r\n      'td:nth-child(2) .star .pl',\r\n      (el) => el.textContent?.replace(/\\(|\\)/g, '')\r\n    )\r\n\r\n    pendingTask.push([\r\n      namePending,\r\n      picturePending,\r\n      infoPending,\r\n      scorePending,\r\n      commentsNumberPending\r\n    ])\r\n  }\r\n\r\n  const filmInfoResult = []\r\n  let i = 0\r\n  for (const item of pendingTask) {\r\n    Promise.all(item).then((res) => {\r\n      // filmInfo 是一个电影信息对象，顺序在前面就决定好了\r\n      const filmInfo = [\r\n        'name',\r\n        'picture',\r\n        'info',\r\n        'score',\r\n        'commentsNumber'\r\n      ].reduce((pre, key, i) => {\r\n        pre[key] = res[i]\r\n        return pre\r\n      }, {})\r\n\r\n      // 保存每个电影信息\r\n      filmInfoResult.push(filmInfo)\r\n\r\n      // 最后一次的处理\r\n      if (pendingTask.length === ++i) {\r\n        browser.close()\r\n\r\n        // 整理，根据数量决定是多还是单\r\n        const filmResult = {\r\n          element: filmInfoResult,\r\n          type: filmInfoResult.length > 1 ? 'multiple' : 'single'\r\n        }\r\n\r\n        console.log(filmResult)\r\n      }\r\n    })\r\n  }\r\n})\r\n```\r\n\r\n### AI 辅助爬虫\r\n\r\n**爬虫 + AI ，让爬虫和 AI 获取豆瓣电影排行榜的电影信息**\r\n\r\n```js\r\nimport { createCrawl, createCrawlOpenAI } from 'x-crawl'\r\n\r\n// 创建爬虫应用\r\nconst crawlApp = createCrawl()\r\n\r\n// 创建 AI 应用\r\nconst crawlOpenAIApp = createCrawlOpenAI({\r\n  clientOptions: { apiKey: process.env['OPENAI_API_KEY'] },\r\n  defaultModel: { chatModel: 'gpt-4-turbo-preview' }\r\n})\r\n\r\n// crawlPage 用于爬取页面\r\ncrawlApp.crawlPage('https://movie.douban.com/chart').then(async (res) => {\r\n  const { page, browser } = res.data\r\n\r\n  // 等待元素出现在页面中, 并获取 HTML\r\n  await page.waitForSelector('#wrapper #content .article')\r\n  const targetHTML = await page.$eval(\r\n    '#wrapper #content .article',\r\n    (e) => e.outerHTML\r\n  )\r\n\r\n  browser.close()\r\n\r\n  // 让 AI 获取电影信息 (描述越详细越好)\r\n  const filmResult = await crawlOpenAIApp.parseElements(\r\n    targetHTML,\r\n    `这是电影列表, 需要获取电影名(name), 封面链接(picture), 简介(info), 评分(score), 评论人数(commentsNumber)。使用括号的单词作为属性名`\r\n  )\r\n\r\n  console.log(filmResult)\r\n})\r\n```\r\n\r\n#### 两个示例的结果\r\n\r\n两个示例最终展示的电影信息\r\n\r\n```json\r\n{\r\n  \"elements\": [\r\n    {\r\n      \"name\": \"老狐狸\",\r\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2900908599.webp\",\r\n      \"info\": \"2023-10-27(东京国际电影节) / 2023-11-24(中国台湾) / 白润音 / 刘冠廷 / 陈慕义 / 刘奕儿 / 门胁麦 / 黄健玮 / 温升豪 / 班铁翔 / 杨丽音 / 傅孟柏 / 高英轩 / 庄益增 / 张再兴 / 许博维 / 管罄 / 钟瑶 / 游珈瑄 / 郑旸恩 / 戴雅芝 / 姜仁 / 萧鸿文...\",\r\n      \"score\": \"8.1\",\r\n      \"commentsNumber\": \"29211 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"机器人之梦\",\r\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2899644068.webp\",\r\n      \"info\": \"2023-05-20(戛纳电影节) / 2023-12-06(西班牙) / 2024(中国大陆) / 伊万·拉班达 / 阿尔伯特·特里佛·塞加拉 / 拉法·卡尔沃 / 何塞·加西亚·托斯 / 何塞·路易斯·梅地亚维拉 / 加西埃拉·莫利娜 / 埃斯特·索兰斯 / 西班牙 / 法国 / 巴勃罗·贝格尔...\",\r\n      \"score\": \"9.1\",\r\n      \"commentsNumber\": \"64650 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"白日之下\",\r\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2904961420.webp\",\r\n      \"info\": \"2023-06-11(上海国际电影节) / 2023-11-02(中国香港) / 2024-04-12(中国大陆) / 姜大卫 / 余香凝 / 林保怡 / 梁仲恒 / 陈湛文 / 周汉宁 / 梁雍婷 / 龚慈恩 / 宝珮如 / 朱柏谦 / 朱栢康 / 许月湘 / 胡枫 / 鲍起静 / 高翰文 / 彭杏英 / 罗浩铭 / 谭玉瑛...\",\r\n      \"score\": \"8.0\",\r\n      \"commentsNumber\": \"36540 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"可怜的东西\",\r\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2897662939.webp\",\r\n      \"info\": \"2023-09-01(威尼斯电影节) / 2023-12-08(美国) / 艾玛·斯通 / 马克·鲁弗洛 / 威廉·达福 / 拉米·尤素夫 / 克里斯托弗·阿波特 / 苏西·本巴 / 杰洛德·卡尔迈克 / 凯瑟琳·亨特 / 薇琪·佩珀代因 / 玛格丽特·库里 / 汉娜·许古拉 / 杰克·巴顿...\",\r\n      \"score\": \"7.0\",\r\n      \"commentsNumber\": \"130113 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"完美的日子\",\r\n      \"picture\": \"https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2898894527.webp\",\r\n      \"info\": \"2023-05-25(戛纳电影节) / 2023-12-21(德国) / 2023-12-22(日本) / 役所广司 / 柄本时生 / 中野有纱 / 山田葵  / 麻生祐未 / 石川小百合 / 三浦友和 / 田中泯 / 大下浩人 / 犬山犬子 / 牧口元美 / 长井短 / 研直子 / 茂吕师冈 / 县森鱼 / 片桐入 / 芹泽兴人...\",\r\n      \"score\": \"8.3\",\r\n      \"commentsNumber\": \"33562 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"新威龙杀阵\",\r\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2905374090.webp\",\r\n      \"info\": \"2024-03-08(西南偏南电影节) / 2024-03-21(美国网络) / 杰克·吉伦哈尔 / 康纳·麦格雷戈 / 杰西卡·威廉姆斯 / 比利·马格努森 / 丹妮拉·曼希沃 / 吉米索拉·艾库美罗 / 卢卡斯·盖奇 / 特拉维斯·范·文克 / 达伦·巴内特 / 乔昆姆·德·阿尔梅达...\",\r\n      \"score\": \"6.3\",\r\n      \"commentsNumber\": \"9980 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"首尔之春\",\r\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2905204009.webp\",\r\n      \"info\": \"2023-11-22(韩国) / 黄政民 / 郑雨盛 / 李星民 / 朴解浚 / 金成畇 / 朴勋 / 安世镐 / 郑允荷 / 丁海寅 / 南允皓 / 全秀芝 / 韩国 / 金成洙 / 141 分钟 / 首尔之春 / 剧情 / 金成洙 Sung-su Kim / 韩语\",\r\n      \"score\": \"8.8\",\r\n      \"commentsNumber\": \"171858 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"金手指\",\r\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2901830629.webp\",\r\n      \"info\": \"2023-12-30(中国大陆) / 梁朝伟 / 刘德华 / 蔡卓妍 / 任达华 / 方中信 / 陈家乐 / 白只 / 姜皓文 / 太保 / 钱嘉乐 / 袁咏仪 / 周家怡 / 岑珈其 / 李靖筠 / 吴肇轩 / 柯炜林 / 冯泳贤 / 杜曜宇 / 李建城 / 古永锋 / 中国香港 / 中国大陆 / 庄文强...\",\r\n      \"score\": \"6.1\",\r\n      \"commentsNumber\": \"135956 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"美国小说\",\r\n      \"picture\": \"https://img9.doubanio.com/view/photo/s_ratio_poster/public/p2902166424.webp\",\r\n      \"info\": \"2023-09-08(多伦多国际电影节) / 2023-12-15(美国) / 杰弗里·怀特 / 翠西·艾利斯·罗斯 / 约翰·奥提兹 / 伊萨·雷 / 斯特林·K·布朗 / 埃里卡·亚历山大 / 莱斯利·格塞斯 / 亚当·布罗迪 / 凯斯·大卫 / 迈拉·卢克利希亚·泰勒 / 雷蒙德·安东尼·托马斯...\",\r\n      \"score\": \"7.7\",\r\n      \"commentsNumber\": \"26223 人评价\"\r\n    },\r\n    {\r\n      \"name\": \"利益区域\",\r\n      \"picture\": \"https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2899514583.webp\",\r\n      \"info\": \"2023-05-19(戛纳电影节) / 2023-12-15(美国) / 克里斯蒂安·富里道尔 / 桑德拉·惠勒 / 约翰·卡特豪斯 / 拉尔夫·赫尔福特 / 弗雷娅·克罗伊茨卡姆 / 马克斯·贝克 / 伊摩根·蔻格 / 斯蒂芬妮·佩特罗维茨 / 拉尔夫·齐尔曼 / 玛丽·罗莎·提特言...\",\r\n      \"score\": \"7.4\",\r\n      \"commentsNumber\": \"24875 人评价\"\r\n    }\r\n  ],\r\n  \"type\": \"multiple\"\r\n}\r\n```\r\n\r\n### 比较\r\n\r\n#### 传统爬虫提取信息所需的步骤\r\n\r\n```js\r\nconst pendingTask = []\r\nfor (const filmHandle of filmHandleList) {\r\n  const picturePending = filmHandle.$eval('td img', (img) => img.src)\r\n  const namePending = filmHandle.$eval(\r\n    'td:nth-child(2) a',\r\n    (el) => el.innerText.split(' / ')[0]\r\n  )\r\n  const infoPending = filmHandle.$eval(\r\n    'td:nth-child(2) .pl',\r\n    (el) => el.textContent\r\n  )\r\n  const scorePending = filmHandle.$eval(\r\n    'td:nth-child(2) .star .rating_nums',\r\n    (el) => el.textContent\r\n  )\r\n  const commentsNumberPending = filmHandle.$eval(\r\n    'td:nth-child(2) .star .pl',\r\n    (el) => el.textContent?.replace(/\\(|\\)/g, '')\r\n  )\r\n\r\n  pendingTask.push([\r\n    namePending,\r\n    picturePending,\r\n    infoPending,\r\n    scorePending,\r\n    commentsNumberPending\r\n  ])\r\n}\r\n\r\nconst filmInfoResult = []\r\nlet i = 0\r\nfor (const item of pendingTask) {\r\n  Promise.all(item).then((res) => {\r\n    const filmInfo =\r\n      ['name', 'picture', 'info', 'score', 'commentsNumber'].reduce <\r\n      any >\r\n      ((pre, key, i) => {\r\n        pre[key] = res[i]\r\n        return pre\r\n      },\r\n      {})\r\n\r\n    filmInfoResult.push(filmInfo)\r\n\r\n    if (pendingTask.length === ++i) {\r\n      const filmResult = {\r\n        element: filmInfoResult,\r\n        type: filmInfoResult.length > 1 ? 'multiple' : 'single'\r\n      }\r\n    }\r\n  })\r\n}\r\n```\r\n\r\n依靠固定的类名和结构，过程还是比较繁琐的。\r\n\r\n#### AI 辅助爬虫提取信息所需的步骤\r\n\r\n```js\r\nconst filmResult = await crawlOpenAIApp.parseElements(\r\n  targetHTML,\r\n  `这是电影列表, 需要获取电影名(name), 封面链接(picture), 简介(info), 评分(score), 评论人数(commentsNumber)。使用括号的单词作为属性名`\r\n)\r\n```\r\n\r\n一句话的事。\r\n\r\n---\r\n\r\n- `传统爬虫` 需要依靠 `“固定的类名”` 和 `“各种繁琐的操作”` 来获取数据，如果网站更新频繁，那么网站更新后类名或结构的改变可能导致传统的爬虫抓取策略失效，需要重新获取最新的类名以及更新各种操作才能爬取数据。\r\n- `AI 辅助爬虫` 只需要 `“一段话”` 就能够更加高效、智能和便捷获取到所需的数据。甚至可以将整个 HTML 传给 AI 帮我们操作，由于网站内容更加复杂需要更准确描述要取的位置，并且会消耗大量的 Tokens ，但即使网站后续的更新导致类名或结构发生改变也能正常爬到数据，因为我们可以不再依赖于固定的类名或结构来定位并提取所需信息，而是让 AI 理解并解析网页的语义信息，从而更高效、智能和便捷提取所需数据。\r\n\r\n> 如果所需的内容更多，那么传统爬虫所做的步骤也就更多，而 AI 辅助爬虫只需增加几句话就能搞定，并且不用担心网站更新后的类名和结构是否会发生改动。\r\n\r\n## 总结\r\n\r\n传统爬虫主要依赖于预设的规则或模式来抓取网页数据，它们对于结构稳定、规则明确的网站表现出色。然而，随着网络技术的飞速发展和网站结构的频繁更新，传统爬虫面临着越来越多的挑战。一旦网站结构发生变化，传统爬虫通常需要重新调整规则，甚至可能导致抓取失败，这大大降低了其效率和准确性。\r\n\r\n相比之下，AI 辅助爬虫结合了人工智能技术，能够智能地解析网页结构和语义，自适应网站的变化。通过机器学习和自然语言处理等技术，AI 辅助爬虫可以识别并学习网页中的特征，从而更准确地定位和提取所需数据。这使得 AI 辅助爬虫在面对复杂多变的网站结构时，能够保持高效的抓取能力。\r\n\r\n总的来说，传统爬虫和 AI 辅助爬虫各有其适用场景。对于结构稳定、规则明确的网站，传统爬虫可能是一个更经济、更直接的选择。然而，对于结构复杂、频繁更新的网站，AI 辅助爬虫则展现出了更高的灵活性和准确性优势。在选择时，我们需要根据具体的抓取需求、网站特点以及资源投入等因素进行综合考虑。\r\n\r\n## 资源\r\n\r\n文中示例中所用到的爬虫都是来自 x-crawl ，不管是传统爬虫还是 AI 辅助爬虫它都可以满足您，并且还拥有很多好用的功能。\r\n\r\n### x-crawl\r\n\r\nx-crawl 是一个灵活的 Node.js AI 辅助爬虫库。灵活的使用方式和强大的 AI 辅助功能，使爬虫工作变得更加高效、智能和便捷。\r\n\r\n它由两部分组成：\r\n\r\n- 爬虫：由爬虫 API 以及各种功能组成，即使不依靠 AI 也能正常工作。\r\n- AI：目前基于 OpenAI 提供的 AI 大模型，让 AI 简化很多繁琐的操作。\r\n\r\n### 特征\r\n\r\n-   **🤖 AI 辅助** - 强大的 AI 辅助功能，使爬虫工作变得更加高效、智能和便捷。\r\n-   **🖋️ 写法灵活** - 单个爬取 API 都适配多种配置，每种配置方式都各有千秋。\r\n-   **⚙️ 多种用途** - 支持爬动态页面、静态页面、接口数据以及文件数据。\r\n-   **⚒️ 控制页面** - 爬取动态页面支持自动化操作、键盘输入、事件操作等。\r\n-   **👀 设备指纹** - 零配置或自定义配置，避免指纹识别从不同位置识别并跟踪我们。\r\n-   **🔥 异步同步** - 无需切换爬取 API 即可进行异步或同步的爬取模式。\r\n-   **⏱️ 间隔爬取** - 无间隔、固定间隔以及随机间隔，决定是否高并发爬取。\r\n-   **🔄 失败重试** - 自定义重试次数，避免因短暂的问题而造成爬取失败。\r\n-   **➡️ 轮换代理** - 搭配失败重试，自定义错误次数以及 HTTP 状态码自动轮换代理。\r\n-   **🚀 优先队列** - 根据单个爬取目标的优先级可以优先于其他目标提前爬取。\r\n-   **🧾 爬取信息** - 可控的爬取信息，会在终端输出彩色字符串信息。\r\n-   **🦾 TypeScript** - 拥有类型，通过泛型实现完整的类型。\r\n\r\n> 如果您觉得 x-crawl 对您有所帮助，或者您喜欢 x-crawl ，可以在 GitHub 上给  [x-crawl 存储库]( https://github.com/coder-hxl/x-crawl)  点个 star 。您的支持是我们持续改进的动力！感谢您的支持！\r\n\r\n**x-crawl GitHub: https://github.com/coder-hxl/x-crawl**\r\n\r\n**x-crawl 文档: https://coder-hxl.github.io/x-crawl/cn/**", "content_rendered": "<h2>前言</h2>\n<p>在数据抓取领域，传统爬虫与 AI 辅助爬虫各有千秋。传统爬虫基于规则进行数据抓取，适用于结构稳定、规则明确的网站。然而，随着网站结构的频繁变动和复杂化，传统爬虫逐渐暴露出其局限性。相比之下，AI 辅助爬虫借助人工智能技术，能够智能解析网页、自适应变化，展现出更高的灵活性和准确性。那么，面对不同的抓取需求，我们该如何选择呢？本文将深入探讨传统爬虫与 AI 辅助爬虫的特点与优劣，为您提供决策参考。</p>\n<h2>传统爬虫 和 AI 辅助爬虫 分别是什么</h2>\n<h3>传统爬虫</h3>\n<p>传统爬虫主要依赖于固定的规则或模式来抓取网页数据。它们通常通过识别网页中的特定元素，如类名、标签或结构，来定位和提取所需信息。然而，这种方式的局限性显而易见。一旦网站进行更新，改变了原有的类名、标签或结构，传统爬虫就会因为无法识别新的元素而失效，导致数据抓取失败或错误。</p>\n<h3>AI 辅助爬虫</h3>\n<p>AI 辅助爬虫能够智能地分析和理解网页内容，从而更准确地定位并提取所需信息。通过自然语言处理等技术，它们能够理解网页的语义信息，从而更精确地定位所需数据，即使网站进行了更新，AI 辅助爬虫也能继续有效地抓取数据。</p>\n<h2>示例</h2>\n<p>选用大家熟悉的豆瓣来进行示范，而爬虫则是用 <a href=\"https://github.com/coder-hxl/x-crawl\" rel=\"nofollow\">x-crawl</a> 。</p>\n<ul>\n<li>传统爬虫，通过网页中的特定元素获取豆瓣电影排行榜的电影信息</li>\n<li>爬虫 + AI ，爬虫搭配 AI 获取豆瓣电影排行榜的电影信息</li>\n</ul>\n<h3>传统爬虫</h3>\n<p><strong>传统爬虫，通过网页中的特定元素获取豆瓣电影排行榜的电影信息</strong></p>\n<pre><code class=\"language-js\">import { createCrawl } from 'x-crawl'\n\n// 创建爬虫应用\nconst crawlApp = createCrawl()\n\n// crawlPage 用于爬取页面\ncrawlApp.crawlPage('https://movie.douban.com/chart').then(async (res) =&gt; {\n  const { page, browser } = res.data\n\n  // 等待元素出现在页面中\n  await page.waitForSelector('#wrapper #content .article')\n  const filmHandleList = await page.$$('#wrapper #content .article table')\n\n  const pendingTask = []\n  for (const filmHandle of filmHandleList) {\n    // 封面链接(picture)\n    const picturePending = filmHandle.$eval('td img', (img) =&gt; img.src)\n    // 电影名(name)\n    const namePending = filmHandle.$eval(\n      'td:nth-child(2) a',\n      (el) =&gt; el.innerText.split(' / ')[0]\n    )\n    // 简介(info)\n    const infoPending = filmHandle.$eval(\n      'td:nth-child(2) .pl',\n      (el) =&gt; el.textContent\n    )\n    // 评分(score)\n    const scorePending = filmHandle.$eval(\n      'td:nth-child(2) .star .rating_nums',\n      (el) =&gt; el.textContent\n    )\n    // 评论人数(commentsNumber)\n    const commentsNumberPending = filmHandle.$eval(\n      'td:nth-child(2) .star .pl',\n      (el) =&gt; el.textContent?.replace(/\\(|\\)/g, '')\n    )\n\n    pendingTask.push([\n      namePending,\n      picturePending,\n      infoPending,\n      scorePending,\n      commentsNumberPending\n    ])\n  }\n\n  const filmInfoResult = []\n  let i = 0\n  for (const item of pendingTask) {\n    Promise.all(item).then((res) =&gt; {\n      // filmInfo 是一个电影信息对象，顺序在前面就决定好了\n      const filmInfo = [\n        'name',\n        'picture',\n        'info',\n        'score',\n        'commentsNumber'\n      ].reduce((pre, key, i) =&gt; {\n        pre[key] = res[i]\n        return pre\n      }, {})\n\n      // 保存每个电影信息\n      filmInfoResult.push(filmInfo)\n\n      // 最后一次的处理\n      if (pendingTask.length === ++i) {\n        browser.close()\n\n        // 整理，根据数量决定是多还是单\n        const filmResult = {\n          element: filmInfoResult,\n          type: filmInfoResult.length &gt; 1 ? 'multiple' : 'single'\n        }\n\n        console.log(filmResult)\n      }\n    })\n  }\n})\n</code></pre>\n<h3>AI 辅助爬虫</h3>\n<p><strong>爬虫 + AI ，让爬虫和 AI 获取豆瓣电影排行榜的电影信息</strong></p>\n<pre><code class=\"language-js\">import { createCrawl, createCrawlOpenAI } from 'x-crawl'\n\n// 创建爬虫应用\nconst crawlApp = createCrawl()\n\n// 创建 AI 应用\nconst crawlOpenAIApp = createCrawlOpenAI({\n  clientOptions: { apiKey: process.env['OPENAI_API_KEY'] },\n  defaultModel: { chatModel: 'gpt-4-turbo-preview' }\n})\n\n// crawlPage 用于爬取页面\ncrawlApp.crawlPage('https://movie.douban.com/chart').then(async (res) =&gt; {\n  const { page, browser } = res.data\n\n  // 等待元素出现在页面中, 并获取 HTML\n  await page.waitForSelector('#wrapper #content .article')\n  const targetHTML = await page.$eval(\n    '#wrapper #content .article',\n    (e) =&gt; e.outerHTML\n  )\n\n  browser.close()\n\n  // 让 AI 获取电影信息 (描述越详细越好)\n  const filmResult = await crawlOpenAIApp.parseElements(\n    targetHTML,\n    `这是电影列表, 需要获取电影名(name), 封面链接(picture), 简介(info), 评分(score), 评论人数(commentsNumber)。使用括号的单词作为属性名`\n  )\n\n  console.log(filmResult)\n})\n</code></pre>\n<h4>两个示例的结果</h4>\n<p>两个示例最终展示的电影信息</p>\n<pre><code class=\"language-json\">{\n  \"elements\": [\n    {\n      \"name\": \"老狐狸\",\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2900908599.webp\",\n      \"info\": \"2023-10-27(东京国际电影节) / 2023-11-24(中国台湾) / 白润音 / 刘冠廷 / 陈慕义 / 刘奕儿 / 门胁麦 / 黄健玮 / 温升豪 / 班铁翔 / 杨丽音 / 傅孟柏 / 高英轩 / 庄益增 / 张再兴 / 许博维 / 管罄 / 钟瑶 / 游珈瑄 / 郑旸恩 / 戴雅芝 / 姜仁 / 萧鸿文...\",\n      \"score\": \"8.1\",\n      \"commentsNumber\": \"29211 人评价\"\n    },\n    {\n      \"name\": \"机器人之梦\",\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2899644068.webp\",\n      \"info\": \"2023-05-20(戛纳电影节) / 2023-12-06(西班牙) / 2024(中国大陆) / 伊万·拉班达 / 阿尔伯特·特里佛·塞加拉 / 拉法·卡尔沃 / 何塞·加西亚·托斯 / 何塞·路易斯·梅地亚维拉 / 加西埃拉·莫利娜 / 埃斯特·索兰斯 / 西班牙 / 法国 / 巴勃罗·贝格尔...\",\n      \"score\": \"9.1\",\n      \"commentsNumber\": \"64650 人评价\"\n    },\n    {\n      \"name\": \"白日之下\",\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2904961420.webp\",\n      \"info\": \"2023-06-11(上海国际电影节) / 2023-11-02(中国香港) / 2024-04-12(中国大陆) / 姜大卫 / 余香凝 / 林保怡 / 梁仲恒 / 陈湛文 / 周汉宁 / 梁雍婷 / 龚慈恩 / 宝珮如 / 朱柏谦 / 朱栢康 / 许月湘 / 胡枫 / 鲍起静 / 高翰文 / 彭杏英 / 罗浩铭 / 谭玉瑛...\",\n      \"score\": \"8.0\",\n      \"commentsNumber\": \"36540 人评价\"\n    },\n    {\n      \"name\": \"可怜的东西\",\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2897662939.webp\",\n      \"info\": \"2023-09-01(威尼斯电影节) / 2023-12-08(美国) / 艾玛·斯通 / 马克·鲁弗洛 / 威廉·达福 / 拉米·尤素夫 / 克里斯托弗·阿波特 / 苏西·本巴 / 杰洛德·卡尔迈克 / 凯瑟琳·亨特 / 薇琪·佩珀代因 / 玛格丽特·库里 / 汉娜·许古拉 / 杰克·巴顿...\",\n      \"score\": \"7.0\",\n      \"commentsNumber\": \"130113 人评价\"\n    },\n    {\n      \"name\": \"完美的日子\",\n      \"picture\": \"https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2898894527.webp\",\n      \"info\": \"2023-05-25(戛纳电影节) / 2023-12-21(德国) / 2023-12-22(日本) / 役所广司 / 柄本时生 / 中野有纱 / 山田葵  / 麻生祐未 / 石川小百合 / 三浦友和 / 田中泯 / 大下浩人 / 犬山犬子 / 牧口元美 / 长井短 / 研直子 / 茂吕师冈 / 县森鱼 / 片桐入 / 芹泽兴人...\",\n      \"score\": \"8.3\",\n      \"commentsNumber\": \"33562 人评价\"\n    },\n    {\n      \"name\": \"新威龙杀阵\",\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2905374090.webp\",\n      \"info\": \"2024-03-08(西南偏南电影节) / 2024-03-21(美国网络) / 杰克·吉伦哈尔 / 康纳·麦格雷戈 / 杰西卡·威廉姆斯 / 比利·马格努森 / 丹妮拉·曼希沃 / 吉米索拉·艾库美罗 / 卢卡斯·盖奇 / 特拉维斯·范·文克 / 达伦·巴内特 / 乔昆姆·德·阿尔梅达...\",\n      \"score\": \"6.3\",\n      \"commentsNumber\": \"9980 人评价\"\n    },\n    {\n      \"name\": \"首尔之春\",\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2905204009.webp\",\n      \"info\": \"2023-11-22(韩国) / 黄政民 / 郑雨盛 / 李星民 / 朴解浚 / 金成畇 / 朴勋 / 安世镐 / 郑允荷 / 丁海寅 / 南允皓 / 全秀芝 / 韩国 / 金成洙 / 141 分钟 / 首尔之春 / 剧情 / 金成洙 Sung-su Kim / 韩语\",\n      \"score\": \"8.8\",\n      \"commentsNumber\": \"171858 人评价\"\n    },\n    {\n      \"name\": \"金手指\",\n      \"picture\": \"https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2901830629.webp\",\n      \"info\": \"2023-12-30(中国大陆) / 梁朝伟 / 刘德华 / 蔡卓妍 / 任达华 / 方中信 / 陈家乐 / 白只 / 姜皓文 / 太保 / 钱嘉乐 / 袁咏仪 / 周家怡 / 岑珈其 / 李靖筠 / 吴肇轩 / 柯炜林 / 冯泳贤 / 杜曜宇 / 李建城 / 古永锋 / 中国香港 / 中国大陆 / 庄文强...\",\n      \"score\": \"6.1\",\n      \"commentsNumber\": \"135956 人评价\"\n    },\n    {\n      \"name\": \"美国小说\",\n      \"picture\": \"https://img9.doubanio.com/view/photo/s_ratio_poster/public/p2902166424.webp\",\n      \"info\": \"2023-09-08(多伦多国际电影节) / 2023-12-15(美国) / 杰弗里·怀特 / 翠西·艾利斯·罗斯 / 约翰·奥提兹 / 伊萨·雷 / 斯特林·K·布朗 / 埃里卡·亚历山大 / 莱斯利·格塞斯 / 亚当·布罗迪 / 凯斯·大卫 / 迈拉·卢克利希亚·泰勒 / 雷蒙德·安东尼·托马斯...\",\n      \"score\": \"7.7\",\n      \"commentsNumber\": \"26223 人评价\"\n    },\n    {\n      \"name\": \"利益区域\",\n      \"picture\": \"https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2899514583.webp\",\n      \"info\": \"2023-05-19(戛纳电影节) / 2023-12-15(美国) / 克里斯蒂安·富里道尔 / 桑德拉·惠勒 / 约翰·卡特豪斯 / 拉尔夫·赫尔福特 / 弗雷娅·克罗伊茨卡姆 / 马克斯·贝克 / 伊摩根·蔻格 / 斯蒂芬妮·佩特罗维茨 / 拉尔夫·齐尔曼 / 玛丽·罗莎·提特言...\",\n      \"score\": \"7.4\",\n      \"commentsNumber\": \"24875 人评价\"\n    }\n  ],\n  \"type\": \"multiple\"\n}\n</code></pre>\n<h3>比较</h3>\n<h4>传统爬虫提取信息所需的步骤</h4>\n<pre><code class=\"language-js\">const pendingTask = []\nfor (const filmHandle of filmHandleList) {\n  const picturePending = filmHandle.$eval('td img', (img) =&gt; img.src)\n  const namePending = filmHandle.$eval(\n    'td:nth-child(2) a',\n    (el) =&gt; el.innerText.split(' / ')[0]\n  )\n  const infoPending = filmHandle.$eval(\n    'td:nth-child(2) .pl',\n    (el) =&gt; el.textContent\n  )\n  const scorePending = filmHandle.$eval(\n    'td:nth-child(2) .star .rating_nums',\n    (el) =&gt; el.textContent\n  )\n  const commentsNumberPending = filmHandle.$eval(\n    'td:nth-child(2) .star .pl',\n    (el) =&gt; el.textContent?.replace(/\\(|\\)/g, '')\n  )\n\n  pendingTask.push([\n    namePending,\n    picturePending,\n    infoPending,\n    scorePending,\n    commentsNumberPending\n  ])\n}\n\nconst filmInfoResult = []\nlet i = 0\nfor (const item of pendingTask) {\n  Promise.all(item).then((res) =&gt; {\n    const filmInfo =\n      ['name', 'picture', 'info', 'score', 'commentsNumber'].reduce &lt;\n      any &gt;\n      ((pre, key, i) =&gt; {\n        pre[key] = res[i]\n        return pre\n      },\n      {})\n\n    filmInfoResult.push(filmInfo)\n\n    if (pendingTask.length === ++i) {\n      const filmResult = {\n        element: filmInfoResult,\n        type: filmInfoResult.length &gt; 1 ? 'multiple' : 'single'\n      }\n    }\n  })\n}\n</code></pre>\n<p>依靠固定的类名和结构，过程还是比较繁琐的。</p>\n<h4>AI 辅助爬虫提取信息所需的步骤</h4>\n<pre><code class=\"language-js\">const filmResult = await crawlOpenAIApp.parseElements(\n  targetHTML,\n  `这是电影列表, 需要获取电影名(name), 封面链接(picture), 简介(info), 评分(score), 评论人数(commentsNumber)。使用括号的单词作为属性名`\n)\n</code></pre>\n<p>一句话的事。</p>\n<hr/>\n<ul>\n<li><code>传统爬虫</code> 需要依靠 <code>“固定的类名”</code> 和 <code>“各种繁琐的操作”</code> 来获取数据，如果网站更新频繁，那么网站更新后类名或结构的改变可能导致传统的爬虫抓取策略失效，需要重新获取最新的类名以及更新各种操作才能爬取数据。</li>\n<li><code>AI 辅助爬虫</code> 只需要 <code>“一段话”</code> 就能够更加高效、智能和便捷获取到所需的数据。甚至可以将整个 HTML 传给 AI 帮我们操作，由于网站内容更加复杂需要更准确描述要取的位置，并且会消耗大量的 Tokens ，但即使网站后续的更新导致类名或结构发生改变也能正常爬到数据，因为我们可以不再依赖于固定的类名或结构来定位并提取所需信息，而是让 AI 理解并解析网页的语义信息，从而更高效、智能和便捷提取所需数据。</li>\n</ul>\n<blockquote>\n<p>如果所需的内容更多，那么传统爬虫所做的步骤也就更多，而 AI 辅助爬虫只需增加几句话就能搞定，并且不用担心网站更新后的类名和结构是否会发生改动。</p>\n</blockquote>\n<h2>总结</h2>\n<p>传统爬虫主要依赖于预设的规则或模式来抓取网页数据，它们对于结构稳定、规则明确的网站表现出色。然而，随着网络技术的飞速发展和网站结构的频繁更新，传统爬虫面临着越来越多的挑战。一旦网站结构发生变化，传统爬虫通常需要重新调整规则，甚至可能导致抓取失败，这大大降低了其效率和准确性。</p>\n<p>相比之下，AI 辅助爬虫结合了人工智能技术，能够智能地解析网页结构和语义，自适应网站的变化。通过机器学习和自然语言处理等技术，AI 辅助爬虫可以识别并学习网页中的特征，从而更准确地定位和提取所需数据。这使得 AI 辅助爬虫在面对复杂多变的网站结构时，能够保持高效的抓取能力。</p>\n<p>总的来说，传统爬虫和 AI 辅助爬虫各有其适用场景。对于结构稳定、规则明确的网站，传统爬虫可能是一个更经济、更直接的选择。然而，对于结构复杂、频繁更新的网站，AI 辅助爬虫则展现出了更高的灵活性和准确性优势。在选择时，我们需要根据具体的抓取需求、网站特点以及资源投入等因素进行综合考虑。</p>\n<h2>资源</h2>\n<p>文中示例中所用到的爬虫都是来自 x-crawl ，不管是传统爬虫还是 AI 辅助爬虫它都可以满足您，并且还拥有很多好用的功能。</p>\n<h3>x-crawl</h3>\n<p>x-crawl 是一个灵活的 Node.js AI 辅助爬虫库。灵活的使用方式和强大的 AI 辅助功能，使爬虫工作变得更加高效、智能和便捷。</p>\n<p>它由两部分组成：</p>\n<ul>\n<li>爬虫：由爬虫 API 以及各种功能组成，即使不依靠 AI 也能正常工作。</li>\n<li>AI：目前基于 OpenAI 提供的 AI 大模型，让 AI 简化很多繁琐的操作。</li>\n</ul>\n<h3>特征</h3>\n<ul>\n<li><strong>🤖 AI 辅助</strong> - 强大的 AI 辅助功能，使爬虫工作变得更加高效、智能和便捷。</li>\n<li><strong>🖋️ 写法灵活</strong> - 单个爬取 API 都适配多种配置，每种配置方式都各有千秋。</li>\n<li><strong>⚙️ 多种用途</strong> - 支持爬动态页面、静态页面、接口数据以及文件数据。</li>\n<li><strong>⚒️ 控制页面</strong> - 爬取动态页面支持自动化操作、键盘输入、事件操作等。</li>\n<li><strong>👀 设备指纹</strong> - 零配置或自定义配置，避免指纹识别从不同位置识别并跟踪我们。</li>\n<li><strong>🔥 异步同步</strong> - 无需切换爬取 API 即可进行异步或同步的爬取模式。</li>\n<li><strong>⏱️ 间隔爬取</strong> - 无间隔、固定间隔以及随机间隔，决定是否高并发爬取。</li>\n<li><strong>🔄 失败重试</strong> - 自定义重试次数，避免因短暂的问题而造成爬取失败。</li>\n<li><strong>➡️ 轮换代理</strong> - 搭配失败重试，自定义错误次数以及 HTTP 状态码自动轮换代理。</li>\n<li><strong>🚀 优先队列</strong> - 根据单个爬取目标的优先级可以优先于其他目标提前爬取。</li>\n<li><strong>🧾 爬取信息</strong> - 可控的爬取信息，会在终端输出彩色字符串信息。</li>\n<li><strong>🦾 TypeScript</strong> - 拥有类型，通过泛型实现完整的类型。</li>\n</ul>\n<blockquote>\n<p>如果您觉得 x-crawl 对您有所帮助，或者您喜欢 x-crawl ，可以在 GitHub 上给  <a href=\"https://github.com/coder-hxl/x-crawl\" rel=\"nofollow\">x-crawl 存储库</a>  点个 star 。您的支持是我们持续改进的动力！感谢您的支持！</p>\n</blockquote>\n<p><strong>x-crawl GitHub: <a href=\"https://github.com/coder-hxl/x-crawl\" rel=\"nofollow\">https://github.com/coder-hxl/x-crawl</a></strong></p>\n<p><strong>x-crawl 文档: <a href=\"https://coder-hxl.github.io/x-crawl/cn/\" rel=\"nofollow\">https://coder-hxl.github.io/x-crawl/cn/</a></strong></p>\n", "last_modified": 1713752125, "replies": 42, "id": 1034501}]